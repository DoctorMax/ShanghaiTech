{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. Reinforcement Learning for BipedalWalker-v3 (35 points)\n",
    "This problem is to design a reinforcement learning algorithm that is applied to a robot, with the objective to maximize its reward, in the following game. \n",
    "### BipedalWalker-v3\n",
    "The reward is given for moving forward, accumulating over 300 points at the end. If the robot falls, it will be penalized by deducting 100 points. Applying a motor torque costs a small amount of points. The state of the robot consists of hull angle speed, angular velocity, horizontal speed, vertical speed, positions of joints, angular speeds of joints, contact positions of legs with the ground, and 10 lidar rangefinder measurements. There is no coordinate in the state vector.  \n",
    "![Alt Text](https://media.giphy.com/media/R89toZzap04ZDKHPkd/giphy.gif)  \n",
    "This game has continuous action space. You are required to apply the Twin Delayed DDPG (TD3) method in this game.  \n",
    "### References：\n",
    "You can read [this link](https://spinningup.openai.com/en/latest/algorithms/td3.html) to understand the **TD3** algorithm better.  \n",
    "You can visit [this link](https://dllglobal.com/challenges/reinforcement-learning) to understand the **BipedalWalker-v3** environment better.  \n",
    "### Requirements：\n",
    "* All of your code should be shown in this file.\n",
    "* Your network must be based on GRU; otherwise, you will get 0 point.\n",
    "* You must save your trained model named as **best_model.pt**.\n",
    "* The RL method you need to implement is TD3; otherwise you will get 0 point.\n",
    "* Please give some comments to your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Import the packages and define helper funcitons and variables (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build your network (<font color=red>which should include GRU cells</font>) (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define your TD3 algorithm (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Define your training process and train your model (5 points)  \n",
    "You must use some data structures to collect the mean reward and mean loss in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Show your change curves of reward and loss in two sub-pictures (5 points)\n",
    "Your reward and loss must be able to converge; otherwise this part will get 0 point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Test your model 10 times and print the mean reward (5 points) \n",
    "You should load your trained model **best_model.pt**. If your mean reward is >= 200 but < 250, you will get 3 points. If your mean reward is >= 250, you will get 5 points. If your mean reward is < 200, you will get 0 point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
