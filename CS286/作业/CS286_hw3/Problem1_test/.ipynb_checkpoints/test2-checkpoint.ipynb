{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. VoxelMorph for Brain Registration (35 points)\n",
    "Although most people’s brains are similar (e.g. everyone has a cingulate gyrus and a corpus callosum), there are also differences in brain size and shape. Hence, if we want to do a group analysis we need to ensure that each voxel for each subject corresponds to the same part of the brains of others. If we are measuring a voxel in the visual cortex, for example, we would want to make sure that every subject’s visual cortex is in alignment with that of another subject. This is done by registering the images. Just as you would fold clothes to fit them inside a suitcase, the brain images of different subjects need to be transformed to have the same size, shape, and dimensions. We do this by normalizing (or warping) the images to a template. A template is a brain image that has standard dimensions and coordinates. Most researchers have agreed to use the templates when reporting their results. \n",
    "#### Reference：\n",
    " \"VoxelMorph: A Learning Framework for Deformable Medical Image Registration\" (https://arxiv.org/pdf/1809.05231.pdf).\n",
    "#### Requirement：\n",
    "All your code should be shown in *problem1.ipynb* (this file). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data loading and preprocessing (6 points)\n",
    "Use \"SimpleITK\" to load the data and resize it to \\[64, 64, 64\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据读取完毕\n",
      "数据读取完毕\n",
      "数据resize完毕\n",
      "数据resize完毕\n",
      "fixed图像resize完毕\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "#先完成读数据的部分，封装成函数能够让主程序看起来清晰易懂\n",
    "def read_image_itk(path):\n",
    "    imgdir = os.listdir(path)\n",
    "    itkImgs = []\n",
    "    imgArrays = []\n",
    "    spacings = []\n",
    "    directions = []\n",
    "    origins = []\n",
    "#     print(path)\n",
    "    for filename in imgdir:\n",
    "#         print(filename)\n",
    "        itk_img = sitk.ReadImage(path + filename)\n",
    "        #读取图像大小\n",
    "        img_array = sitk.GetArrayFromImage(itk_img) # 新增一个通道的维度\n",
    "#         print(\"Img array: \", img_array.shape)               \n",
    "        #读取图像原点坐标\n",
    "        origin = np.array(itk_img.GetOrigin())           \n",
    "#         print(\"Origin (x,y,z): \", origin)\n",
    "        #读取图像方向,采用方向余弦矩阵，也就是图像自身坐标系相对于世界坐标系（固定不动的）的角度，再直白点就是新坐标系在原坐标系上各个方向的投影\n",
    "        direction = np.array(itk_img.GetDirection())\n",
    "#         print(\"Direction: \", direction)\n",
    "        # 读取图像尺度信息,图像各维度上像素之间的距离（物理层面的，有单位，一般为mm)\n",
    "        spacing = np.array(itk_img.GetSpacing())         \n",
    "#         print(\"Spacing (x,y,z): \", spacing)\n",
    "        itkImgs.append(itk_img)\n",
    "        imgArrays.append(img_array)\n",
    "        origins.append(origin)\n",
    "        directions.append(direction)\n",
    "        spacings.append(spacing)\n",
    "    print('数据读取完毕')\n",
    "    return itkImgs,imgArrays,origins,directions,spacings\n",
    "#数据读取函数写完了，返回了常用的几种信息，print部分先注释了，调试的时候再看吧\n",
    "\n",
    "#resize部分\n",
    "def resize_image_itk(itkImgs, newSize, resamplemethod=sitk.sitkNearestNeighbor):\n",
    "    itkimgResampleds=[]\n",
    "    for itk_img in itkImgs:\n",
    "        resampler = sitk.ResampleImageFilter()\n",
    "        originSize = itk_img.GetSize()  # 原来的体素块尺寸\n",
    "        originSpacing = itk_img.GetSpacing()   # 读取图像尺度信息,图像各维度上像素之间的距离（物理层面的，有单位，一般为mm)\n",
    "        newSize = np.array(newSize,float)\n",
    "        factor = originSize / newSize\n",
    "        newSpacing = originSpacing * factor\n",
    "        newSize = newSize.astype(np.int) #spacing肯定不能是整数\n",
    "        resampler.SetReferenceImage(itk_img)  # 需要重新采样的目标图像\n",
    "        resampler.SetSize(newSize.tolist())\n",
    "        resampler.SetOutputSpacing(newSpacing.tolist())\n",
    "        resampler.SetTransform(sitk.Transform(3, sitk.sitkIdentity))\n",
    "        resampler.SetInterpolator(resamplemethod)  #这里要注意：mask用最近邻插值，CT图像用线性插值\n",
    "#         itkimgResampled = resampler.Execute(itk_img)\n",
    "        itkimgResampled = sitk.GetArrayFromImage(resampler.Execute(itk_img))  # 得到重新采样后的图像\n",
    "        itkimgResampleds.append(itkimgResampled)\n",
    "    print('数据resize完毕')\n",
    "    return itkimgResampleds\n",
    "\n",
    "def resize_fixed_itk(itk_img, newSize, resamplemethod=sitk.sitkNearestNeighbor):\n",
    "    itkimgResampleds=[]\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    originSize = itk_img.GetSize()  # 原来的体素块尺寸\n",
    "    originSpacing = itk_img.GetSpacing()   # 读取图像尺度信息,图像各维度上像素之间的距离（物理层面的，有单位，一般为mm)\n",
    "    newSize = np.array(newSize,float)\n",
    "    factor = originSize / newSize\n",
    "    newSpacing = originSpacing * factor\n",
    "    newSize = newSize.astype(np.int) #spacing肯定不能是整数\n",
    "    resampler.SetReferenceImage(itk_img)  # 需要重新采样的目标图像\n",
    "    resampler.SetSize(newSize.tolist())\n",
    "    resampler.SetOutputSpacing(newSpacing.tolist())\n",
    "    resampler.SetTransform(sitk.Transform(3, sitk.sitkIdentity))\n",
    "    resampler.SetInterpolator(resamplemethod)  #这里要注意：mask用最近邻插值，CT图像用线性插值\n",
    "    itkimgResampled = sitk.GetArrayFromImage(resampler.Execute(itk_img))[ np.newaxis, ...] # 得到重新采样后的图像\n",
    "    print('fixed图像resize完毕')\n",
    "    return itkimgResampled\n",
    "\n",
    "#参数设置\n",
    "train_path='./data/train/'\n",
    "mask_path='./data/mask/'\n",
    "atlas_path='./data/fixed.nii.gz'\n",
    "model_dir = './model/'\n",
    "newSize=[64,64,64]\n",
    "#读取和resize\n",
    "trainItkImgs,trainImgArrays,trainOrigins,trainDirections,trainSpacings=read_image_itk(train_path)\n",
    "maskItkImgs,maskImgArrays,maskOrigins,maskDirections,maskSpacings=read_image_itk(mask_path)\n",
    "trainItkImgsResized=resize_image_itk(trainItkImgs, newSize, resamplemethod=sitk.sitkLinear)\n",
    "maskItkImgsResized=resize_image_itk(maskItkImgs, newSize, resamplemethod=sitk.sitkNearestNeighbor)\n",
    "fixedImg=resize_fixed_itk(sitk.ReadImage(atlas_path),newSize, resamplemethod=sitk.sitkLinear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Building the VoxelMorph model (6 points)\n",
    "Hint: You can refer to the original VoxelMorph model in the reference above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置各种参数\n",
    "# 公共参数\n",
    "gpu='0' #选哪个gpu跑\n",
    "atlas_file='./data/fixed.nii.gz' #模板/地图路径\n",
    "model='vm2' #使用第几个模型\n",
    "result_dir='./result' #图像存放路径\n",
    "\n",
    "# 训练参数\n",
    "train_dir='./data/train/' #数据路径\n",
    "lr=4e-4 #学习率\n",
    "n_iter=15000 #迭代次数\n",
    "sim_loss='ncc' #损失函数，用来评估预测结果与输入的相似程度\n",
    "alpha=4\n",
    "lambda_weight=0.01 #平滑损失占总损失函数中的比例\n",
    "batch_size=1 #批大小\n",
    "n_save_iter=5000 #每几次迭代保存模型\n",
    "model_dir='./models/' #模型存储路径\n",
    "log_dir='./log' #日志存储路径\n",
    "\n",
    "# 测试参数\n",
    "# 此处先不填\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "# multichannel=True #是否是多通道图片，还是灰度图\n",
    "\n",
    "# epochs=1500 #代数量\n",
    "# steps_per_epoch=100 #每个代跑几步\n",
    "# load_model='./models/model' #加载的模型的文件\n",
    "# initial_epoch=0 #初始epoch数量，我猜是用来检查程序是否正常工作\n",
    "\n",
    "# enc=[16,32,32,32] #Unet中编码器的层数和结构\n",
    "# dec=[32,32,32,32,32,16,16] #解码器的层数和结构\n",
    "# int_steps=7 #不知道是啥\n",
    "# int_downsize=2 #不知道是啥\n",
    "# bidir=False #是否启用双向损失函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "\n",
    "class U_Network(nn.Module):\n",
    "    def __init__(self, dim, enc_nf, dec_nf, bn=None, full_size=True):\n",
    "        super(U_Network, self).__init__()\n",
    "        self.bn = bn\n",
    "        self.dim = dim\n",
    "        self.enc_nf = enc_nf\n",
    "        self.full_size = full_size\n",
    "        self.vm2 = len(dec_nf) == 7\n",
    "        # Encoder functions\n",
    "        self.enc = nn.ModuleList()\n",
    "        for i in range(len(enc_nf)):\n",
    "            prev_nf = 2 if i == 0 else enc_nf[i - 1]\n",
    "            self.enc.append(self.conv_block(dim, prev_nf, enc_nf[i], 4, 2, batchnorm=bn))\n",
    "        # Decoder functions\n",
    "        self.dec = nn.ModuleList()\n",
    "        self.dec.append(self.conv_block(dim, enc_nf[-1], dec_nf[0], batchnorm=bn))  # 1\n",
    "        self.dec.append(self.conv_block(dim, dec_nf[0] * 2, dec_nf[1], batchnorm=bn))  # 2\n",
    "        self.dec.append(self.conv_block(dim, dec_nf[1] * 2, dec_nf[2], batchnorm=bn))  # 3\n",
    "        self.dec.append(self.conv_block(dim, dec_nf[2] + enc_nf[0], dec_nf[3], batchnorm=bn))  # 4\n",
    "        self.dec.append(self.conv_block(dim, dec_nf[3], dec_nf[4], batchnorm=bn))  # 5\n",
    "\n",
    "        if self.full_size:\n",
    "            self.dec.append(self.conv_block(dim, dec_nf[4] + 2, dec_nf[5], batchnorm=bn))\n",
    "        if self.vm2:\n",
    "            self.vm2_conv = self.conv_block(dim, dec_nf[5], dec_nf[6], batchnorm=bn)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        # One conv to get the flow field\n",
    "        conv_fn = getattr(nn, 'Conv%dd' % dim)\n",
    "        self.flow = conv_fn(dec_nf[-1], dim, kernel_size=3, padding=1)\n",
    "        # Make flow weights + bias small. Not sure this is necessary.\n",
    "        nd = Normal(0, 1e-5)\n",
    "        self.flow.weight = nn.Parameter(nd.sample(self.flow.weight.shape))\n",
    "        self.flow.bias = nn.Parameter(torch.zeros(self.flow.bias.shape))\n",
    "        self.batch_norm = getattr(nn, \"BatchNorm{0}d\".format(dim))(3)\n",
    "\n",
    "    def conv_block(self, dim, in_channels, out_channels, kernel_size=3, stride=1, padding=1, batchnorm=False):\n",
    "        conv_fn = getattr(nn, \"Conv{0}d\".format(dim))\n",
    "        bn_fn = getattr(nn, \"BatchNorm{0}d\".format(dim))\n",
    "        if batchnorm:\n",
    "            layer = nn.Sequential(\n",
    "                conv_fn(in_channels, out_channels, kernel_size, stride=stride, padding=padding),\n",
    "                bn_fn(out_channels),\n",
    "                nn.LeakyReLU(0.2))\n",
    "        else:\n",
    "            layer = nn.Sequential(\n",
    "                conv_fn(in_channels, out_channels, kernel_size, stride=stride, padding=padding),\n",
    "                nn.LeakyReLU(0.2))\n",
    "        return layer\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        x = torch.cat([src, tgt], dim=1)\n",
    "        # Get encoder activations\n",
    "        x_enc = [x]\n",
    "        for i, l in enumerate(self.enc):\n",
    "            x = l(x_enc[-1])\n",
    "            x_enc.append(x)\n",
    "        # Three conv + upsample + concatenate series\n",
    "        y = x_enc[-1]\n",
    "        for i in range(3):\n",
    "            y = self.dec[i](y)\n",
    "            y = self.upsample(y)\n",
    "            y = torch.cat([y, x_enc[-(i + 2)]], dim=1)\n",
    "        # Two convs at full_size/2 res\n",
    "        y = self.dec[3](y)\n",
    "        y = self.dec[4](y)\n",
    "        # Upsample to full res, concatenate and conv\n",
    "        if self.full_size:\n",
    "            y = self.upsample(y)\n",
    "            y = torch.cat([y, x_enc[0]], dim=1)\n",
    "            y = self.dec[5](y)\n",
    "        # Extra conv for vm2\n",
    "        if self.vm2:\n",
    "            y = self.vm2_conv(y)\n",
    "        flow = self.flow(y)\n",
    "        if self.bn:\n",
    "            flow = self.batch_norm(flow)\n",
    "        return flow\n",
    "\n",
    "\n",
    "class SpatialTransformer(nn.Module):\n",
    "    def __init__(self, size, mode='bilinear'):\n",
    "        super(SpatialTransformer, self).__init__()\n",
    "        # Create sampling grid\n",
    "        vectors = [torch.arange(0, s) for s in size]\n",
    "        grids = torch.meshgrid(vectors)\n",
    "        grid = torch.stack(grids)  # y, x, z\n",
    "        grid = torch.unsqueeze(grid, 0)  # add batch\n",
    "        grid = grid.type(torch.FloatTensor)\n",
    "        self.register_buffer('grid', grid)\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, src, flow):\n",
    "        new_locs = self.grid + flow\n",
    "        shape = flow.shape[2:]\n",
    "\n",
    "        # Need to normalize grid values to [-1, 1] for resampler\n",
    "        for i in range(len(shape)):\n",
    "            new_locs[:, i, ...] = 2 * (new_locs[:, i, ...] / (shape[i] - 1) - 0.5)\n",
    "\n",
    "        if len(shape) == 2:\n",
    "            new_locs = new_locs.permute(0, 2, 3, 1)\n",
    "            new_locs = new_locs[..., [1, 0]]\n",
    "        elif len(shape) == 3:\n",
    "            new_locs = new_locs.permute(0, 2, 3, 4, 1)\n",
    "            new_locs = new_locs[..., [2, 1, 0]]\n",
    "\n",
    "        return F.grid_sample(src, new_locs, mode=self.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Defining loss function (8 points)\n",
    "Use NCC (Normalized Cross Correlation) as \"similarity_loss\" and Jacobian constraint as \"smooth_loss\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     6,
     20,
     24,
     32,
     49,
     65,
     77,
     91
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def gradient_loss(s, penalty='l2'):\n",
    "    dy = torch.abs(s[:, :, 1:, :, :] - s[:, :, :-1, :, :])\n",
    "    dx = torch.abs(s[:, :, :, 1:, :] - s[:, :, :, :-1, :])\n",
    "    dz = torch.abs(s[:, :, :, :, 1:] - s[:, :, :, :, :-1])\n",
    "\n",
    "    if (penalty == 'l2'):\n",
    "        dy = dy * dy\n",
    "        dx = dx * dx\n",
    "        dz = dz * dz\n",
    "\n",
    "    d = torch.mean(dx) + torch.mean(dy) + torch.mean(dz)\n",
    "    return d / 3.0\n",
    "\n",
    "\n",
    "def mse_loss(x, y):\n",
    "    return torch.mean((x - y) ** 2)\n",
    "\n",
    "\n",
    "def DSC(pred, target):\n",
    "    smooth = 1e-5\n",
    "    m1 = pred.flatten()\n",
    "    m2 = target.flatten()\n",
    "    intersection = (m1 * m2).sum()\n",
    "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)\n",
    "\n",
    "\n",
    "def ncc_loss(I, J, win=None):\n",
    "    '''\n",
    "    输入大小是[B,C,D,W,H]格式的，在计算ncc时用卷积来实现指定窗口内求和\n",
    "    '''\n",
    "    ndims = len(list(I.size())) - 2\n",
    "    assert ndims in [1, 2, 3], \"volumes should be 1 to 3 dimensions. found: %d\" % ndims\n",
    "    if win is None:\n",
    "        win = [9] * ndims\n",
    "    sum_filt = torch.ones([1, 1, *win]).to(\"cuda:{}\".format(gpu))\n",
    "    pad_no = math.floor(win[0] / 2)\n",
    "    stride = [1] * ndims\n",
    "    padding = [pad_no] * ndims\n",
    "    I_var, J_var, cross = compute_local_sums(I, J, sum_filt, stride, padding, win)\n",
    "    cc = cross * cross / (I_var * J_var + 1e-5)\n",
    "    return -1 * torch.mean(cc)\n",
    "\n",
    "\n",
    "def compute_local_sums(I, J, filt, stride, padding, win):\n",
    "    I2, J2, IJ = I * I, J * J, I * J\n",
    "    I_sum = F.conv3d(I, filt, stride=stride, padding=padding)\n",
    "    J_sum = F.conv3d(J, filt, stride=stride, padding=padding)\n",
    "    I2_sum = F.conv3d(I2, filt, stride=stride, padding=padding)\n",
    "    J2_sum = F.conv3d(J2, filt, stride=stride, padding=padding)\n",
    "    IJ_sum = F.conv3d(IJ, filt, stride=stride, padding=padding)\n",
    "    win_size = np.prod(win)\n",
    "    u_I = I_sum / win_size\n",
    "    u_J = J_sum / win_size\n",
    "    cross = IJ_sum - u_J * I_sum - u_I * J_sum + u_I * u_J * win_size\n",
    "    I_var = I2_sum - 2 * u_I * I_sum + u_I * u_I * win_size\n",
    "    J_var = J2_sum - 2 * u_J * J_sum + u_J * u_J * win_size\n",
    "    return I_var, J_var, cross\n",
    "\n",
    "\n",
    "def cc_loss(x, y):\n",
    "    # 根据互相关公式进行计算\n",
    "    dim = [2, 3, 4]\n",
    "    mean_x = torch.mean(x, dim, keepdim=True)\n",
    "    mean_y = torch.mean(y, dim, keepdim=True)\n",
    "    mean_x2 = torch.mean(x ** 2, dim, keepdim=True)\n",
    "    mean_y2 = torch.mean(y ** 2, dim, keepdim=True)\n",
    "    stddev_x = torch.sum(torch.sqrt(mean_x2 - mean_x ** 2), dim, keepdim=True)\n",
    "    stddev_y = torch.sum(torch.sqrt(mean_y2 - mean_y ** 2), dim, keepdim=True)\n",
    "    return -torch.mean((x - mean_x) * (y - mean_y) / (stddev_x * stddev_y))\n",
    "\n",
    "\n",
    "def Get_Ja(flow):\n",
    "    '''\n",
    "    Calculate the Jacobian value at each point of the displacement map having\n",
    "    size of b*h*w*d*3 and in the cubic volumn of [-1, 1]^3\n",
    "    '''\n",
    "    D_y = (flow[:, 1:, :-1, :-1, :] - flow[:, :-1, :-1, :-1, :])\n",
    "    D_x = (flow[:, :-1, 1:, :-1, :] - flow[:, :-1, :-1, :-1, :])\n",
    "    D_z = (flow[:, :-1, :-1, 1:, :] - flow[:, :-1, :-1, :-1, :])\n",
    "    D1 = (D_x[..., 0] + 1) * ((D_y[..., 1] + 1) * (D_z[..., 2] + 1) - D_z[..., 1] * D_y[..., 2])\n",
    "    D2 = (D_x[..., 1]) * (D_y[..., 0] * (D_z[..., 2] + 1) - D_y[..., 2] * D_x[..., 0])\n",
    "    D3 = (D_x[..., 2]) * (D_y[..., 0] * D_z[..., 1] - (D_y[..., 1] + 1) * D_z[..., 0])\n",
    "    return D1 - D2 + D3\n",
    "\n",
    "\n",
    "def NJ_loss(ypred):\n",
    "    '''\n",
    "    Penalizing locations where Jacobian has negative determinants\n",
    "    '''\n",
    "    Neg_Jac = 0.5 * (torch.abs(Get_Ja(ypred)) - Get_Ja(ypred))\n",
    "    return torch.sum(Neg_Jac)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Model training (8 points)\n",
    "The number of training iterations should be 15000. Save the results (the warped image and deformation field) every 5000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_name:  15000_0.0004_4\n",
      "(1, 64, 64, 64)\n",
      "Number of training images:  30\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 5-dimensional input for 5-dimensional weight [16, 2, 4, 4, 4], but got 4-dimensional input of size [1, 128, 64, 64] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7d4086574bab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-7d4086574bab>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m# Run the data through the model to produce warp and flow field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mflow_m2f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_moving\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fixed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mm2f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSTN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_moving\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflow_m2f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-95e25f0c2ca8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, tgt)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mx_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[0mx_enc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# Three conv + upsample + concatenate series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    571\u001b[0m                             self.dilation, self.groups)\n\u001b[0;32m    572\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 573\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 5-dimensional input for 5-dimensional weight [16, 2, 4, 4, 4], but got 4-dimensional input of size [1, 128, 64, 64] instead"
     ]
    }
   ],
   "source": [
    "# python imports\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "# external imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from torch.optim import Adam\n",
    "import torch.utils.data as Data\n",
    "# internal imports\n",
    "# from Model import losses\n",
    "# from Model.config import args\n",
    "# from Model.datagenerators import Dataset\n",
    "# from Model.model import U_Network, SpatialTransformer\n",
    "\n",
    "\n",
    "# def count_parameters(model):\n",
    "#     model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "#     params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "#     return params\n",
    "\n",
    "\n",
    "def make_dirs():\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "\n",
    "\n",
    "def save_image(img, ref_img, name):\n",
    "    img = sitk.GetImageFromArray(img[0, 0, ...].cpu().detach().numpy())\n",
    "    img.SetOrigin(ref_img.GetOrigin())\n",
    "    img.SetDirection(ref_img.GetDirection())\n",
    "    img.SetSpacing(ref_img.GetSpacing())\n",
    "    sitk.WriteImage(img, os.path.join(result_dir, name))\n",
    "\n",
    "\n",
    "def train():\n",
    "    # 创建需要的文件夹并指定gpu\n",
    "    make_dirs()\n",
    "    device = torch.device('cuda:{}'.format(gpu) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 日志文件\n",
    "    log_name = str(n_iter) + \"_\" + str(lr) + \"_\" + str(alpha)\n",
    "    print(\"log_name: \", log_name)\n",
    "    f = open(os.path.join(log_dir, log_name + \".txt\"), \"w\")\n",
    "\n",
    "    # 读入fixed图像\n",
    "    f_img = sitk.ReadImage(atlas_file)\n",
    "#     input_fixed = sitk.GetArrayFromImage(f_img)[np.newaxis, np.newaxis, ...]\n",
    "    input_fixed=np.array(fixedImg)\n",
    "    print(input_fixed.shape)############################\n",
    "    vol_size = input_fixed.shape[1:]\n",
    "    # [B, C, D, W, H]\n",
    "    input_fixed = np.repeat(input_fixed, batch_size, axis=0)\n",
    "    input_fixed = torch.from_numpy(input_fixed).to(device).float()\n",
    "\n",
    "    # 创建配准网络（UNet）和STN\n",
    "    nf_enc = [16, 32, 32, 32]\n",
    "    if model == \"vm1\":\n",
    "        nf_dec = [32, 32, 32, 32, 8, 8]\n",
    "    else:\n",
    "        nf_dec = [32, 32, 32, 32, 32, 16, 16]\n",
    "    UNet = U_Network(len(vol_size), nf_enc, nf_dec).to(device)\n",
    "    STN = SpatialTransformer(vol_size).to(device)\n",
    "    UNet.train()\n",
    "    STN.train()\n",
    "    # 模型参数个数\n",
    "#     print(\"UNet: \", count_parameters(UNet))\n",
    "#     print(\"STN: \", count_parameters(STN))\n",
    "\n",
    "    # Set optimizer and losses\n",
    "    opt = Adam(UNet.parameters(), lr=lr)\n",
    "#     sim_loss_fn = losses.ncc_loss if sim_loss == \"ncc\" else losses.mse_loss\n",
    "    sim_loss_fn = ncc_loss\n",
    "    grad_loss_fn = gradient_loss\n",
    "\n",
    "    # Get all the names of the training data\n",
    "    train_files = glob.glob(os.path.join(train_dir, '*.nii.gz'))\n",
    "#     DS = Dataset(files=train_files)\n",
    "#     DS=torch.tensor(trainImgArrays)\n",
    "    DS=torch.tensor(trainItkImgsResized)\n",
    "    print(\"Number of training images: \", len(DS))\n",
    "    DL = Data.DataLoader(DS, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "    # Training loop.\n",
    "    for i in range(1, n_iter + 1):\n",
    "        # Generate the moving images and convert them to tensors.\n",
    "        input_moving = iter(DL).next()\n",
    "        # [B, C, D, W, H]\n",
    "        input_moving = input_moving.to(device).float()\n",
    "\n",
    "        # Run the data through the model to produce warp and flow field\n",
    "        flow_m2f = UNet(input_moving, input_fixed)\n",
    "        m2f = STN(input_moving, flow_m2f)\n",
    "\n",
    "        # Calculate loss\n",
    "        sim_loss = sim_loss_fn(m2f, input_fixed)\n",
    "        grad_loss = grad_loss_fn(flow_m2f)\n",
    "        loss = sim_loss + alpha * grad_loss\n",
    "        print(\"i: %d  loss: %f  sim: %f  grad: %f\" % (i, loss.item(), sim_loss.item(), grad_loss.item()), flush=True)\n",
    "        print(\"%d, %f, %f, %f\" % (i, loss.item(), sim_loss.item(), grad_loss.item()), file=f)\n",
    "\n",
    "        # Backwards and optimize\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if i % n_save_iter == 0:\n",
    "            # Save model checkpoint\n",
    "            save_file_name = os.path.join(model_dir, '%d.pth' % i)\n",
    "            torch.save(UNet.state_dict(), save_file_name)\n",
    "            # Save images\n",
    "            m_name = str(i) + \"_m.nii.gz\"\n",
    "            m2f_name = str(i) + \"_m2f.nii.gz\"\n",
    "            save_image(input_moving, f_img, m_name)\n",
    "            save_image(m2f, f_img, m2f_name)\n",
    "            print(\"warped images have saved.\")\n",
    "    f.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1.5 Visualization of results (2 points)\n",
    "Display the last saved result, consisting of the moving image, fixed image and deformation field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Improving performance (5 points)\n",
    "Hint: Use the given masks corresponding to the training images as the auxiliary information for training the VoxelMorph model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
