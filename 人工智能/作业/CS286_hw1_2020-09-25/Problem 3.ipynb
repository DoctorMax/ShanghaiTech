{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3. SVM (25 points)\n",
    "\n",
    "In this section we have two exercises:\n",
    "1. Implement the SVM Kernels.\n",
    "2. Implement the multiclass C-SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ddigimon/anaconda3/envs/TC-GPU/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cvxopt\n",
    "from scipy.stats import logistic\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "data_set = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 SVM Kernels (15 points)\n",
    "In practice, SVM algorithm is implemented with a kernel that transforms an input data space into the required form. SVM uses a technique called the kernel trick in which the kernel transforms the data from a low-dimensional input space into a higher-dimensional space. In other words, kernel converts non-separable problems into separable problems by adding more dimensions to it. It makes SVM more powerful, flexible and accurate. The following are some of the types of kernels used by SVM.\n",
    "### Linear Kernel\n",
    "It can be used as a dot product between any two observations. The formula of linear kernel is as below:\n",
    "$$ K(x,x_i)=sum(x‚àóx_i)$$\n",
    "From the above formula, we can see that the product between two vectors say $ùë•$ & $ùë•_ùëñ$ is the sum of the multiplication of each pair of input values.\n",
    "### Polynomial Kernel\n",
    "It is more generalized form of linear kernel and distinguish curved or nonlinear input space. Following is the formula for polynomial kernelÔºö\n",
    "$$k(x,x_i)=sum(x‚àóx_i)^d$$\n",
    "Here $d$ is the degree of polynomial, which we need to specify manually in the learning algorithm.\n",
    "### Radial Basis Function (RBF) Kernel\n",
    "RBF kernel, mostly used in SVM classification, maps input space in indefinite dimensional space. Following formula explains it mathematically:\n",
    "$$k(x,x_i)=exp(‚àígamma‚àó||x‚àíx_i||^2)$$\n",
    "Here, gamma ranges from 0 to 1. We need to manually specify it in the learning algorithm. A good default value of gamma is 0.1.\n",
    "As we implemented SVM for linearly separable data, we can implement it in Python for the data that is not linearly separable. It can be done by using kernels.\n",
    "### Implement\n",
    "You need to complete the ``build_kernel`` function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Poly kernel with parameters Y=train_data_set and d=1.\n",
      "\n",
      "[[40.26 54.6  48.04 ... 45.6  49.37 53.34]\n",
      " [54.6  96.58 83.2  ... 80.79 85.34 94.04]\n",
      " [48.04 83.2  72.2  ... 70.05 73.93 81.  ]\n",
      " ...\n",
      " [45.6  80.79 70.05 ... 68.09 71.71 78.62]\n",
      " [49.37 85.34 73.93 ... 71.71 75.79 83.05]\n",
      " [53.34 94.04 81.   ... 78.62 83.05 91.62]]\n",
      "-------------------------------------------------------\n",
      "Linear kernel with parameter Y=train_data_set.\n",
      "\n",
      "[[40.26 54.6  48.04 ... 45.6  49.37 53.34]\n",
      " [54.6  96.58 83.2  ... 80.79 85.34 94.04]\n",
      " [48.04 83.2  72.2  ... 70.05 73.93 81.  ]\n",
      " ...\n",
      " [45.6  80.79 70.05 ... 68.09 71.71 78.62]\n",
      " [49.37 85.34 73.93 ... 71.71 75.79 83.05]\n",
      " [53.34 94.04 81.   ... 78.62 83.05 91.62]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "Test of error warning:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (120,4) and (2,80) not aligned: 4 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-184bbf801166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test of error warning:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mpoly_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_kernel_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'poly'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-184bbf801166>\u001b[0m in \u001b[0;36mbuild_kernel_first\u001b[0;34m(data_set, d, Y, kernel_type)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_kernel_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rbf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkernel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rbf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# put your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (120,4) and (2,80) not aligned: 4 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Y is a variable, which the user has to define. \n",
    "#Similarly the user has to define d, which is the dimension of the polynomial kernel\n",
    "\n",
    "train_data_set, test_data_set, train_labels, test_labels = train_test_split(\n",
    "    data_set, labels, test_size=0.2, random_state=15)\n",
    "\n",
    "# print(data_set)\n",
    "\n",
    "def build_kernel_first(data_set, d, Y, kernel_type = 'rbf'):\n",
    "    kernel = np.dot(data_set, Y.T)\n",
    "    if kernel_type == 'rbf':\n",
    "        # put your code here\n",
    "        ##########################################################\n",
    "        n=len(data_set)\n",
    "        for j in range(n):\n",
    "            for i in range(n):\n",
    "                kernel[i,j]=np.exp(-0.1*np.sum(np.power((data_set[i,:]-Y[j,:]),2)))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##########################################################\n",
    "    elif kernel_type == 'poly':\n",
    "        data_set_features = np.array(data_set).shape[1]\n",
    "        Y_features = np.array(Y).shape[1]\n",
    "        \n",
    "        if data_set_features != Y_features:\n",
    "            n = data_set_features - Y_features\n",
    "            print(\"Warning ! Wrong shape of Y.\",n,\"extra columns of zeros where automatically added to Y in place of missing features!\")\n",
    "            print(\"You should add more features to Y data_set. Currently there are only\",Y_features,\"features!\\n\")\n",
    "            b = np.zeros((np.array(Y).shape[0], Y_features+n))\n",
    "            b[:,:-n] = Y\n",
    "            Y=b\n",
    "        # put your code here\n",
    "        #########################################################\n",
    "        \n",
    "        kernel = np.power(np.dot(data_set, Y.T),d)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##########################################################\n",
    "    return kernel\n",
    "\n",
    "\n",
    "#Here comparing linear_kernel with poly_kernel with parameters Y=train_data_set and d=1.\n",
    "#The output should be the should be the same.\n",
    "\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Poly kernel with parameters Y=train_data_set and d=1.\\n\")\n",
    "poly_kernel = build_kernel_first(train_data_set, d=1, Y=train_data_set, kernel_type='poly')\n",
    "print(poly_kernel)\n",
    "\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Linear kernel with parameter Y=train_data_set.\\n\")\n",
    "linear_kernel = build_kernel_first(train_data_set, d=1, Y=train_data_set, kernel_type='linear')\n",
    "print(linear_kernel)\n",
    "\n",
    "print(\"\\n-------------------------------------------------------\")\n",
    "print(\"Test of error warning:\")\n",
    "Y = np.ones(shape = [80, 2])\n",
    "poly_kernel = build_kernel_first(train_data_set, d=1, Y=Y, kernel_type='poly')\n",
    "print(poly_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3.2 Implement a multiclass C-SVM (10 points)\n",
    "\n",
    "Use the IRIS dataset loaded above to build a multiclass C-SVM classifier. The implementation needs a function that returns the proper dataset to be used for the prediction. You need to implement:\n",
    "- ``choose_set_for_label``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def choose_set_for_label(data_set1, labels1, treshold, other):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "        You need to use \"train_test_split\" function to divide data_set1 (test_ size=0.2, random_ state=15), And compare the label with the threshold\n",
    "        Ôºà< treshold = -1Ôºå>= treshold =1Ôºâ\n",
    "    '''\n",
    "    #put your code here\n",
    "    ##########################################################\n",
    "    train_data_set, test_data_set, train_labels, test_labels = train_test_split(data_set, labels, test_size=0.2, random_state=15)\n",
    "    print(train_labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(np.shape(train_data_set))\n",
    "    print(np.shape(test_data_set))\n",
    "    print(np.shape(train_labels))\n",
    "    print(np.shape(test_labels))\n",
    "    train_data_set=np.delete(train_data_set,np.where(train_labels==other),axis=0)\n",
    "    test_data_set=np.delete(test_data_set,np.where(test_labels==other),axis=0)\n",
    "    train_labels=np.delete(train_labels,np.where(train_labels==other),axis=0)\n",
    "    test_labels=np.delete(test_labels,np.where(test_labels==other),axis=0) \n",
    "#     for i in range(len(train_labels)):\n",
    "#         if train_labels[i]<treshold:\n",
    "#             train_labels[i]=-1\n",
    "#         else:\n",
    "#             train_labels[i]=1\n",
    "#     for i in range(len(test_labels)):\n",
    "#         if test_labels[i]<treshold:\n",
    "#             test_labels[i]=-1\n",
    "#         else:\n",
    "#             test_labels[i]=1\n",
    "    train_labels[train_labels<treshold]=-1\n",
    "    train_labels[train_labels>=treshold]=1\n",
    "    test_labels[test_labels<treshold]=-1\n",
    "    test_labels[test_labels>=treshold]=1\n",
    "    print(np.shape(train_data_set))\n",
    "    print(np.shape(test_data_set))\n",
    "    print(np.shape(train_labels))\n",
    "    print(np.shape(test_labels))\n",
    "    \n",
    "    \n",
    "    print(train_labels)\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    return train_data_set, test_data_set, train_labels, test_labels\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to test your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kernel(data_set, kernel_type='rbf'):\n",
    "    kernel = np.dot(data_set, data_set.T)\n",
    "    if kernel_type == 'rbf':\n",
    "        sigma = 1.0\n",
    "        objects_count = len(data_set)\n",
    "        b = np.ones((len(data_set), 1))\n",
    "        kernel -= 0.5 * (np.dot((np.diag(kernel)*np.ones((1, objects_count))).T, b.T)\n",
    "                         + np.dot(b, (np.diag(kernel) * np.ones((1, objects_count))).T.T))\n",
    "        kernel = np.exp(kernel / (2. * sigma ** 2))\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def train(train_data_set, train_labels, kernel_type='linear', C=10, threshold=1e-5):\n",
    "    kernel = build_kernel(train_data_set, kernel_type=kernel_type)\n",
    "\n",
    "    objects_count = len(train_labels)\n",
    "    \n",
    "    P = train_labels * train_labels.transpose() * kernel\n",
    "    q = -np.ones((objects_count, 1))\n",
    "    G = np.concatenate((np.eye(objects_count), -np.eye(objects_count)))\n",
    "    h = np.concatenate((C * np.ones((objects_count, 1)), np.zeros((objects_count, 1))))\n",
    "\n",
    "    A = train_labels.reshape(1, objects_count)\n",
    "    A = A.astype(float)\n",
    "    b = 0.0\n",
    "\n",
    "    sol = cvxopt.solvers.qp(cvxopt.matrix(P), cvxopt.matrix(q), cvxopt.matrix(G), cvxopt.matrix(h), cvxopt.matrix(A), cvxopt.matrix(b))\n",
    "\n",
    "    lambdas = np.array(sol['x'])\n",
    "\n",
    "    support_vectors_id = np.where(lambdas > threshold)[0]\n",
    "    vector_number = len(support_vectors_id)\n",
    "    support_vectors = train_data_set[support_vectors_id, :]\n",
    "\n",
    "    lambdas = lambdas[support_vectors_id]\n",
    "    targets = train_labels[support_vectors_id]\n",
    "\n",
    "    b = np.sum(targets)\n",
    "    for n in range(vector_number):\n",
    "        b -= np.sum(lambdas * targets * np.reshape(kernel[support_vectors_id[n], support_vectors_id], (vector_number, 1)))\n",
    "    b /= len(lambdas)\n",
    "\n",
    "    return lambdas, support_vectors, support_vectors_id, b, targets, vector_number\n",
    "\n",
    "\n",
    "\n",
    "def classify_rbf(test_data_set, train_data_set, lambdas, targets, b, vector_number, support_vectors, support_vectors_id):\n",
    "    kernel = np.dot(test_data_set, support_vectors.T)\n",
    "    sigma = 1.0\n",
    "    #K = np.dot(test_data_set, support_vectors.T)\n",
    "    #kernel = build_kernel(train_data_set, kernel_type='rbf')\n",
    "    c = (1. / sigma * np.sum(test_data_set ** 2, axis=1) * np.ones((1, np.shape(test_data_set)[0]))).T\n",
    "    c = np.dot(c, np.ones((1, np.shape(kernel)[1])))\n",
    "    #aa = np.dot((np.diag(K)*np.ones((1,len(test_data_set)))).T[support_vectors_id], np.ones((1, np.shape(K)[0]))).T\n",
    "    sv = (np.diag(np.dot(train_data_set, train_data_set.T))*np.ones((1,len(train_data_set)))).T[support_vectors_id]\n",
    "    aa = np.dot(sv,np.ones((1,np.shape(kernel)[0]))).T\n",
    "    kernel = kernel - 0.5 * c - 0.5 * aa\n",
    "    kernel = np.exp(kernel / (2. * sigma ** 2))\n",
    "\n",
    "    y = np.zeros((np.shape(test_data_set)[0], 1))\n",
    "    for j in range(np.shape(test_data_set)[0]):\n",
    "        for i in range(vector_number):\n",
    "            y[j] += lambdas[i] * targets[i] * kernel[j, i]\n",
    "        y[j] += b\n",
    "    return np.sign(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 2 0 0 2 0 0 1 2 0 0 1 2 2 0 1 0 2 2 2 2 1 1 1 0 1 2 2 2 2 0 2 1 2 1\n",
      " 0 1 0 0 2 1 1 1 1 0 2 2 2 0 1 0 0 2 2 1 1 2 1 0 0 1 1 1 0 2 0 1 0 1 0 2 2\n",
      " 2 0 1 0 0 1 0 2 2 2 1 0 0 2 0 1 1 2 1 1 1 0 0 2 1 0 2 1 0 2 1 0 0 0 0 2 0\n",
      " 1 0 0 2 1 2 2 2 2]\n",
      "(120, 4)\n",
      "(30, 4)\n",
      "(120,)\n",
      "(30,)\n",
      "(79, 4)\n",
      "(21, 4)\n",
      "(79,)\n",
      "(21,)\n",
      "[-1  1 -1 -1 -1 -1  1 -1 -1  1 -1  1 -1  1  1  1 -1  1 -1  1  1 -1  1 -1\n",
      " -1  1  1  1  1 -1 -1  1 -1 -1  1  1  1 -1 -1  1  1  1 -1 -1  1 -1  1 -1\n",
      " -1  1 -1 -1  1 -1  1 -1 -1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1  1 -1 -1\n",
      " -1 -1 -1  1 -1 -1  1]\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  9.7422e+01 -1.2078e+03  2e+03  1e-01  2e-15\n",
      " 1:  5.8366e+01 -1.1635e+02  2e+02  5e-03  2e-15\n",
      " 2:  6.8336e+00 -1.6241e+01  2e+01  8e-16  2e-15\n",
      " 3: -5.6850e-01 -3.7348e+00  3e+00  3e-16  8e-16\n",
      " 4: -1.1961e+00 -1.8222e+00  6e-01  2e-16  3e-16\n",
      " 5: -1.4074e+00 -1.6708e+00  3e-01  2e-16  3e-16\n",
      " 6: -1.4699e+00 -1.5619e+00  9e-02  2e-16  3e-16\n",
      " 7: -1.5055e+00 -1.5176e+00  1e-02  2e-16  3e-16\n",
      " 8: -1.5104e+00 -1.5107e+00  3e-04  2e-16  3e-16\n",
      " 9: -1.5105e+00 -1.5105e+00  3e-06  2e-16  3e-16\n",
      "10: -1.5105e+00 -1.5105e+00  3e-08  3e-16  3e-16\n",
      "Optimal solution found.\n",
      "\n",
      "-------------------------------------------------------\n",
      "Accuracy for Setosa vs VersiColor\n",
      "threshold_label =  1 , exclude class with id = 2 :\n",
      "0.8571428571428571\n",
      "-------------------------------------------------------\n",
      "\n",
      "DONE\n",
      "[0 2 1 2 0 0 2 0 0 1 2 0 0 1 2 2 0 1 0 2 2 2 2 1 1 1 0 1 2 2 2 2 0 2 1 2 1\n",
      " 0 1 0 0 2 1 1 1 1 0 2 2 2 0 1 0 0 2 2 1 1 2 1 0 0 1 1 1 0 2 0 1 0 1 0 2 2\n",
      " 2 0 1 0 0 1 0 2 2 2 1 0 0 2 0 1 1 2 1 1 1 0 0 2 1 0 2 1 0 2 1 0 0 0 0 2 0\n",
      " 1 0 0 2 1 2 2 2 2]\n",
      "(120, 4)\n",
      "(30, 4)\n",
      "(120,)\n",
      "(30,)\n",
      "(83, 4)\n",
      "(17, 4)\n",
      "(83,)\n",
      "(17,)\n",
      "[-1  1  1 -1 -1  1 -1 -1  1 -1 -1  1  1 -1 -1  1  1  1  1 -1  1  1  1  1\n",
      " -1  1  1 -1 -1 -1  1 -1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1  1 -1 -1 -1\n",
      "  1  1  1 -1 -1 -1 -1  1  1  1 -1 -1  1 -1  1 -1 -1  1 -1  1 -1  1 -1 -1\n",
      " -1 -1  1 -1 -1 -1  1  1  1  1  1]\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.1018e+02 -1.3048e+03  2e+03  1e-01  2e-15\n",
      " 1:  6.3619e+01 -1.3140e+02  2e+02  5e-03  2e-15\n",
      " 2:  7.4212e+00 -1.8227e+01  3e+01  2e-16  2e-15\n",
      " 3: -7.5526e-01 -4.2505e+00  3e+00  2e-16  7e-16\n",
      " 4: -1.4448e+00 -2.3610e+00  9e-01  2e-16  3e-16\n",
      " 5: -1.7579e+00 -2.0547e+00  3e-01  1e-16  3e-16\n",
      " 6: -1.8128e+00 -1.9053e+00  9e-02  2e-16  3e-16\n",
      " 7: -1.8413e+00 -1.8718e+00  3e-02  3e-16  3e-16\n",
      " 8: -1.8504e+00 -1.8527e+00  2e-03  2e-16  3e-16\n",
      " 9: -1.8512e+00 -1.8513e+00  5e-05  2e-16  3e-16\n",
      "10: -1.8513e+00 -1.8513e+00  1e-06  2e-16  3e-16\n",
      "Optimal solution found.\n",
      "\n",
      "-------------------------------------------------------\n",
      "Accuracy for Setosa vs Virginica\n",
      "threshold_label =  1.5 , exclude class with id = 1 :\n",
      "0.47058823529411764\n",
      "-------------------------------------------------------\n",
      "\n",
      "DONE\n",
      "[0 2 1 2 0 0 2 0 0 1 2 0 0 1 2 2 0 1 0 2 2 2 2 1 1 1 0 1 2 2 2 2 0 2 1 2 1\n",
      " 0 1 0 0 2 1 1 1 1 0 2 2 2 0 1 0 0 2 2 1 1 2 1 0 0 1 1 1 0 2 0 1 0 1 0 2 2\n",
      " 2 0 1 0 0 1 0 2 2 2 1 0 0 2 0 1 1 2 1 1 1 0 0 2 1 0 2 1 0 2 1 0 0 0 0 2 0\n",
      " 1 0 0 2 1 2 2 2 2]\n",
      "(120, 4)\n",
      "(30, 4)\n",
      "(120,)\n",
      "(30,)\n",
      "(78, 4)\n",
      "(22, 4)\n",
      "(78,)\n",
      "(22,)\n",
      "[ 1 -1  1  1 -1  1 -1  1  1 -1  1  1  1  1 -1 -1 -1 -1  1  1  1  1  1 -1\n",
      "  1 -1 -1  1 -1 -1 -1 -1  1  1  1 -1  1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1\n",
      "  1  1  1 -1 -1  1  1  1 -1  1 -1 -1  1 -1 -1 -1  1 -1  1 -1  1 -1  1 -1\n",
      "  1 -1  1  1  1  1]\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  8.1368e+01 -1.3274e+03  3e+03  2e-01  2e-15\n",
      " 1:  5.6550e+01 -1.2265e+02  2e+02  6e-03  2e-15\n",
      " 2:  7.3591e+00 -1.6069e+01  2e+01  1e-15  2e-15\n",
      " 3: -3.6328e-01 -3.5955e+00  3e+00  2e-16  1e-15\n",
      " 4: -1.0880e+00 -1.7230e+00  6e-01  2e-16  4e-16\n",
      " 5: -1.2291e+00 -1.4226e+00  2e-01  2e-16  3e-16\n",
      " 6: -1.2892e+00 -1.4054e+00  1e-01  2e-16  2e-16\n",
      " 7: -1.3235e+00 -1.3522e+00  3e-02  2e-16  3e-16\n",
      " 8: -1.3334e+00 -1.3351e+00  2e-03  2e-16  3e-16\n",
      " 9: -1.3342e+00 -1.3342e+00  3e-05  2e-16  3e-16\n",
      "10: -1.3342e+00 -1.3342e+00  3e-07  2e-16  3e-16\n",
      "Optimal solution found.\n",
      "\n",
      "-------------------------------------------------------\n",
      "Accuracy for Virginica vs Versicolor\n",
      "threshold_label =  2 , exclude class with id = 0 :\n",
      "0.5909090909090909\n",
      "-------------------------------------------------------\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "treshold=[1,1.5,2]\n",
    "#1->(Setosa vs Versicolor), 1.5->(Setosa vs Virginica), 2->(Virginica vs Versicolor)\n",
    "other=[2,1,0] #which class is excluded, we consider pairs only\n",
    "names=['Setosa vs VersiColor', 'Setosa vs Virginica', 'Virginica vs Versicolor']\n",
    "\n",
    "for i, (tr,oth) in enumerate(zip(treshold, other)):\n",
    "    \n",
    "    data_set1 = np.copy(data_set)\n",
    "    labels1 = np.copy(labels)\n",
    "    \n",
    "    train_data_set_1, test_data_set_1, train_labels_1, test_labels_1 =\\\n",
    "    choose_set_for_label(data_set1, labels1, tr, oth)\n",
    "\n",
    "    #objects_count = len(train_data_set)\n",
    "    lambdas, support_vectors, support_vectors_id, b, targets, vector_number =\\\n",
    "    train(train_data_set_1, train_labels_1, kernel_type='rbf')\n",
    "\n",
    "\n",
    "    predicted = classify_rbf(test_data_set_1, train_data_set_1, lambdas,\\\n",
    "                                                targets, b, vector_number, support_vectors, support_vectors_id)\n",
    "    predicted = list(predicted.astype(int))\n",
    "    print(\"\\n-------------------------------------------------------\")         \n",
    "    print(\"Accuracy for\", names[i])\n",
    "    print(\"threshold_label = \", tr,\", exclude class with id =\", oth,\":\")\n",
    "    \n",
    "    print(accuracy_score(predicted, test_labels_1))\n",
    "    print(\"-------------------------------------------------------\\n\")\n",
    "    print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
