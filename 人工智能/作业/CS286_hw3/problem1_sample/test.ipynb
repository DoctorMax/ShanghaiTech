{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal python imports\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "# third party imports\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "from skimage import measure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "from torch.distributions.normal import Normal\n",
    "import inspect\n",
    "import functools\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import nibabel as nib\n",
    "\n",
    "#这啥？\n",
    "# # local/our imports\n",
    "# import pystrum.pynd.ndutils as nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     3,
     53,
     91,
     119,
     168,
     190,
     222
    ]
   },
   "outputs": [],
   "source": [
    "#Generators\n",
    "\n",
    "\n",
    "def volgen(\n",
    "        vol_names,\n",
    "        batch_size=1, \n",
    "        return_segs=False,\n",
    "        np_var='vol',\n",
    "        pad_shape=None,\n",
    "        resize_factor=1,\n",
    "        add_feat_axis=True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Base generator for random volume loading. Volumes can be passed as a path to\n",
    "    the parent directory, a glob pattern or a list of file paths. Corresponding\n",
    "    segmentations are additionally loaded if return_segs is set to True. If\n",
    "    loading segmentations, npz files with variable names 'vol' and 'seg' are\n",
    "    expected.\n",
    "\n",
    "    Parameters:\n",
    "        vol_names: Path, glob pattern or list of volume files to load.\n",
    "        batch_size: Batch size. Default is 1.\n",
    "        return_segs: Loads corresponding segmentations. Default is False.\n",
    "        np_var: Name of the volume variable if loading npz files. Default is 'vol'.\n",
    "        pad_shape: Zero-pads loaded volumes to a given shape. Default is None.\n",
    "        resize_factor: Volume resize factor. Default is 1.\n",
    "        add_feat_axis: Load volume arrays with added feature axis. Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    # convert glob path to filenames\n",
    "    if isinstance(vol_names, str):\n",
    "        if os.path.isdir(vol_names):\n",
    "            vol_names = os.path.join(vol_names, '*')\n",
    "        vol_names = glob.glob(vol_names)\n",
    "\n",
    "    while True:\n",
    "        # generate [batchsize] random image indices\n",
    "        indices = np.random.randint(len(vol_names), size=batch_size)\n",
    "\n",
    "        # load volumes and concatenate\n",
    "        load_params = dict(np_var=np_var, add_batch_axis=True, add_feat_axis=add_feat_axis, pad_shape=pad_shape, resize_factor=resize_factor)\n",
    "        imgs = [load_volfile(vol_names[i], **load_params) for i in indices]\n",
    "        vols = [np.concatenate(imgs, axis=0)]\n",
    "\n",
    "        # optionally load segmentations and concatenate\n",
    "        if return_segs:\n",
    "            load_params['np_var'] = 'seg'  # be sure to load seg\n",
    "            segs = [load_volfile(vol_names[i], **load_params) for i in indices]\n",
    "            vols.append(np.concatenate(segs, axis=0))\n",
    "\n",
    "        yield tuple(vols)\n",
    "\n",
    "\n",
    "def scan_to_scan(vol_names, bidir=False, batch_size=1, prob_same=0, no_warp=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Generator for scan-to-scan registration.\n",
    "\n",
    "    Parameters:\n",
    "        vol_names: List of volume files to load.\n",
    "        bidir: Yield input image as output for bidirectional models. Default is False.\n",
    "        batch_size: Batch size. Default is 1.\n",
    "        prob_same: Induced probability that source and target inputs are the same. Default is 0.\n",
    "        no_warp: Excludes null warp in output list if set to True (for affine training). Default if False.\n",
    "        kwargs: Forwarded to the internal volgen generator.\n",
    "    \"\"\"\n",
    "    zeros = None\n",
    "    gen = volgen(vol_names, batch_size=batch_size, **kwargs)\n",
    "    while True:\n",
    "        scan1 = next(gen)[0]\n",
    "        scan2 = next(gen)[0]\n",
    "\n",
    "        # some induced chance of making source and target equal\n",
    "        if prob_same > 0 and np.random.rand() < prob_same:\n",
    "            if np.random.rand() > 0.5:\n",
    "                scan1 = scan2\n",
    "            else:\n",
    "                scan2 = scan1\n",
    "\n",
    "        # cache zeros\n",
    "        if not no_warp and zeros is None:\n",
    "            shape = scan1.shape[1:-1]\n",
    "            zeros = np.zeros((batch_size, *shape, len(shape)))\n",
    "\n",
    "        invols  = [scan1, scan2]\n",
    "        outvols = [scan2, scan1] if bidir else [scan2]\n",
    "        if not no_warp:\n",
    "            outvols.append(zeros)\n",
    "\n",
    "        yield (invols, outvols)\n",
    "\n",
    "\n",
    "def scan_to_atlas(vol_names, atlas, bidir=False, batch_size=1, no_warp=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Generator for scan-to-atlas registration.\n",
    "\n",
    "    TODO: This could be merged into scan_to_scan() by adding an optional atlas\n",
    "    argument like in semisupervised().\n",
    "\n",
    "    Parameters:\n",
    "        vol_names: List of volume files to load.\n",
    "        atlas: Atlas volume data.\n",
    "        bidir: Yield input image as output for bidirectional models. Default is False.\n",
    "        batch_size: Batch size. Default is 1.\n",
    "        no_warp: Excludes null warp in output list if set to True (for affine training). Default if False.\n",
    "        kwargs: Forwarded to the internal volgen generator.\n",
    "    \"\"\"\n",
    "    shape = atlas.shape[1:-1]\n",
    "    zeros = np.zeros((batch_size, *shape, len(shape)))\n",
    "    atlas = np.repeat(atlas, batch_size, axis=0)\n",
    "    gen = volgen(vol_names, batch_size=batch_size, **kwargs)\n",
    "    while True:\n",
    "        scan = next(gen)[0]\n",
    "        invols  = [scan, atlas]\n",
    "        outvols = [atlas, scan] if bidir else [atlas]\n",
    "        if not no_warp:\n",
    "            outvols.append(zeros)\n",
    "        yield (invols, outvols)\n",
    "\n",
    "\n",
    "def semisupervised(vol_names, labels, atlas_file=None, downsize=2):\n",
    "    \"\"\"\n",
    "    Generator for semi-supervised registration training using ground truth segmentations.\n",
    "    Scan-to-atlas training can be enabled by providing the atlas_file argument. It's\n",
    "    expected that vol_names and atlas_file are npz files with both 'vol' and 'seg' arrays.\n",
    "\n",
    "    Parameters:\n",
    "        vol_names: List of volume npz files to load.\n",
    "        labels: Array of discrete label values to use in training.\n",
    "        atlas_file: Atlas npz file for scan-to-atlas training. Default is None.\n",
    "        downsize: Downsize factor for segmentations. Default is 2.\n",
    "    \"\"\"\n",
    "    # configure base generator\n",
    "    gen = volgen(vol_names, return_segs=True, np_var='vol')\n",
    "    zeros = None\n",
    "\n",
    "    # internal utility to generate downsampled prob seg from discrete seg\n",
    "    def split_seg(seg):\n",
    "        prob_seg = np.zeros((*seg.shape[:4], len(labels)))\n",
    "        for i, label in enumerate(labels):\n",
    "            prob_seg[0, ..., i] = seg[0, ..., 0] == label\n",
    "        return prob_seg[:, ::downsize, ::downsize, ::downsize, :]\n",
    "\n",
    "    # cache target vols and segs if atlas is supplied\n",
    "    if atlas_file:\n",
    "        trg_vol = py.utils.load_volfile(atlas_file, np_var='vol', add_batch_axis=True, add_feat_axis=True)\n",
    "        trg_seg = py.utils.load_volfile(atlas_file, np_var='seg', add_batch_axis=True, add_feat_axis=True)\n",
    "        trg_seg = split_seg(trg_seg)\n",
    "\n",
    "    while True:\n",
    "        # load source vol and seg\n",
    "        src_vol, src_seg = next(gen)\n",
    "        src_seg = split_seg(src_seg)\n",
    "\n",
    "        # load target vol and seg (if not provided by atlas)\n",
    "        if not atlas_file:\n",
    "            trg_vol, trg_seg = next(gen)\n",
    "            trg_seg = split_seg(trg_seg)\n",
    "\n",
    "        # cache zeros\n",
    "        if zeros is None:\n",
    "            shape = src_vol.shape[1:-1]\n",
    "            zeros = np.zeros((1, *shape, len(shape)))\n",
    "\n",
    "        invols  = [src_vol, trg_vol, src_seg]\n",
    "        outvols = [trg_vol, zeros,   trg_seg]\n",
    "        yield (invols, outvols)\n",
    "\n",
    "\n",
    "def template_creation(vol_names, atlas, bidir=False, batch_size=1, **kwargs):\n",
    "    \"\"\"\n",
    "    Generator for unconditional template creation.\n",
    "\n",
    "    Parameters:\n",
    "        vol_names: List of volume files to load.\n",
    "        atlas: Atlas input volume data.\n",
    "        bidir: Yield input image as output for bidirectional models. Default is False.\n",
    "        batch_size: Batch size. Default is 1.\n",
    "        kwargs: Forwarded to the internal volgen generator.\n",
    "    \"\"\"\n",
    "    shape = atlas.shape[1:-1]\n",
    "    zeros = np.zeros((batch_size, *shape, len(shape)))\n",
    "    atlas = np.repeat(atlas, batch_size, axis=0)\n",
    "    gen = volgen(vol_names, batch_size=batch_size, **kwargs)\n",
    "    while True:\n",
    "        scan = next(gen)[0]\n",
    "        invols  = [atlas, scan]  # TODO: this is opposite of the normal ordering and might be confusing\n",
    "        outvols = [scan, atlas, zeros, zeros] if bidir else [scan, zeros, zeros]\n",
    "        yield (invols, outvols)\n",
    "\n",
    "\n",
    "def conditional_template_creation(vol_names, atlas, attributes, batch_size=1, np_var='vol', pad_shape=None, add_feat_axis=True):\n",
    "    \"\"\"\n",
    "    Generator for conditional template creation.\n",
    "\n",
    "    Parameters:\n",
    "        vol_names: List of volume files to load.\n",
    "        atlas: Atlas input volume data.\n",
    "        attributes: Dictionary of phenotype data for each vol name.\n",
    "        batch_size: Batch size. Default is 1.\n",
    "        np_var: Name of the volume variable if loading npz files. Default is 'vol'.\n",
    "        pad_shape: Zero-pads loaded volumes to a given shape. Default is None.\n",
    "        add_feat_axis: Load volume arrays with added feature axis. Default is True.\n",
    "    \"\"\"\n",
    "    shape = atlas.shape[1:-1]\n",
    "    zeros = np.zeros((batch_size, *shape, len(shape)))\n",
    "    atlas = np.repeat(atlas, batch_size, axis=0)\n",
    "    while True:\n",
    "        indices = np.random.randint(len(vol_names), size=batch_size)\n",
    "\n",
    "        # load pheno from attributes dictionary\n",
    "        pheno = np.stack([attributes[vol_names[i]] for i in indices], axis=0)\n",
    "\n",
    "        # load volumes and concatenate\n",
    "        load_params = dict(np_var=np_var, add_batch_axis=True, add_feat_axis=add_feat_axis, pad_shape=pad_shape)\n",
    "        vols = [py.utils.load_volfile(vol_names[i], **load_params) for i in indices]\n",
    "        vols = np.concatenate(vols, axis=0)\n",
    "\n",
    "        invols  = [pheno, atlas, vols]\n",
    "        outvols = [vols, zeros, zeros, zeros]\n",
    "        yield (invols, outvols)\n",
    "\n",
    "\n",
    "def surf_semisupervised(\n",
    "        vol_names,\n",
    "        atlas_vol,\n",
    "        atlas_seg,\n",
    "        nb_surface_pts,\n",
    "        labels=None,\n",
    "        batch_size=1,\n",
    "        surf_bidir=True,\n",
    "        surface_pts_upsample_factor=2,\n",
    "        smooth_seg_std=1,\n",
    "        nb_labels_sample=None,\n",
    "        sdt_vol_resize=1,\n",
    "        align_segs=False,\n",
    "        add_feat_axis=True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Scan-to-atlas generator for semi-supervised learning using surface point clouds from segmentations.\n",
    "\n",
    "    Parameters:\n",
    "        vol_names: List of volume files to load.\n",
    "        atlas_vol: Atlas volume array.\n",
    "        atlas_seg: Atlas segmentation array.\n",
    "        nb_surface_pts: Total number surface points for all structures.\n",
    "        labels: Label list to include. If None, all labels in atlas_seg are used. Default is None.\n",
    "        batch_size: Batch size. NOTE some features only implemented for 1. Default is 1.\n",
    "        surf_bidir: Train with bidirectional surface distance. Default is True.\n",
    "        surface_pts_upsample_factor: Upsample factor for surface pointcloud. Default is 2.\n",
    "        smooth_seg_std: Segmentation smoothness sigma. Default is 1.\n",
    "        nb_labels_sample: Number of labels to sample. Default is None.\n",
    "        sdt_vol_resize: Resize factor for signed distance transform volumes. Default is 1.\n",
    "        align_segs: Whether to pass in segmentation image instead. Default is False.\n",
    "        add_feat_axis: Load volume arrays with added feature axis. Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    # some input checks\n",
    "    assert nb_surface_pts > 0, 'number of surface point should be greater than 0'\n",
    "\n",
    "    # prepare some shapes\n",
    "    vol_shape = atlas_seg.shape\n",
    "    sdt_shape = [int(f * sdt_vol_resize) for f in vol_shape]\n",
    "\n",
    "    # compute labels from atlas, and the number of labels to sample.\n",
    "    if labels is not None:\n",
    "        atlas_seg = py.utils.filter_labels(atlas_seg, labels)\n",
    "    else:\n",
    "        labels = np.sort(np.unique(atlas_seg))[1:]\n",
    "\n",
    "    # use all labels by default\n",
    "    if nb_labels_sample is None:\n",
    "        nb_labels_sample = len(labels)\n",
    "\n",
    "    # prepare keras format atlases\n",
    "    atlas_vol_bs = np.repeat(atlas_vol[np.newaxis, ..., np.newaxis], batch_size, axis=0)\n",
    "    atlas_seg_bs = np.repeat(atlas_seg[np.newaxis, ..., np.newaxis], batch_size, axis=0)\n",
    "\n",
    "    # prepare surface extraction function\n",
    "    std_to_surf = lambda x, y: py.utils.sdt_to_surface_pts(x, y, surface_pts_upsample_factor=surface_pts_upsample_factor, thr=(1/surface_pts_upsample_factor + 1e-5))\n",
    "    \n",
    "    # prepare zeros, which will be used for outputs unused in cost functions\n",
    "    zero_flow = np.zeros((batch_size, *vol_shape, len(vol_shape)))\n",
    "    zero_surface_values = np.zeros((batch_size, nb_surface_pts, 1))\n",
    "\n",
    "    # precompute label edge volumes\n",
    "    atlas_sdt = [None] * len(labels) \n",
    "    atlas_label_vols = [None] * len(labels) \n",
    "    nb_edges = np.zeros(len(labels))\n",
    "    for li, label in enumerate(labels):  # if only one label, get surface points here\n",
    "        atlas_label_vols[li] = atlas_seg == label\n",
    "        atlas_label_vols[li] = py.utils.clean_seg(atlas_label_vols[li], smooth_seg_std)\n",
    "        atlas_sdt[li] = py.utils.vol_to_sdt(atlas_label_vols[li], sdt=True, sdt_vol_resize=sdt_vol_resize)\n",
    "        nb_edges[li] = np.sum(np.abs(atlas_sdt[li]) < 1.01)\n",
    "    layer_edge_ratios = nb_edges / np.sum(nb_edges)\n",
    "\n",
    "    # if working with all the labels passed in (i.e. no label sampling per batch), \n",
    "    # pre-compute the atlas surface points\n",
    "    atlas_surface_pts = np.zeros((batch_size, nb_surface_pts, len(vol_shape) + 1))\n",
    "    if nb_labels_sample == len(labels):\n",
    "        nb_surface_pts_sel = py.utils.get_surface_pts_per_label(nb_surface_pts, layer_edge_ratios)\n",
    "        for li, label in enumerate(labels):  # if only one label, get surface points here\n",
    "            atlas_surface_pts_ = std_to_surf(atlas_sdt[li], nb_surface_pts_sel[li])[np.newaxis, ...]\n",
    "            # get the surface point stack indexes for this element\n",
    "            srf_idx = slice(int(np.sum(nb_surface_pts_sel[:li])), int(np.sum(nb_surface_pts_sel[:li + 1])))\n",
    "            atlas_surface_pts[:, srf_idx, :-1] = np.repeat(atlas_surface_pts_, batch_size, 0)\n",
    "            atlas_surface_pts[:, srf_idx,  -1] = li\n",
    "\n",
    "    # generator\n",
    "    gen = volgen(vol_names, return_segs=True, batch_size=batch_size, add_feat_axis=add_feat_axis)\n",
    "    \n",
    "    assert batch_size == 1, 'only batch size 1 supported for now'\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # prepare data\n",
    "        X = next(gen)\n",
    "        X_img = X[0]\n",
    "        X_seg = py.utils.filter_labels(X[1], labels)\n",
    "\n",
    "        # get random labels\n",
    "        sel_label_idxs = range(len(labels))  # all labels\n",
    "        if nb_labels_sample != len(labels):\n",
    "            sel_label_idxs = np.sort(np.random.choice(range(len(labels)), size=nb_labels_sample, replace=False))\n",
    "            sel_layer_edge_ratios = [layer_edge_ratios[li] for li in sel_label_idxs]\n",
    "            nb_surface_pts_sel = py.utils.get_surface_pts_per_label(nb_surface_pts, sel_layer_edge_ratios)\n",
    "                \n",
    "        # prepare signed distance transforms and surface point arrays\n",
    "        X_sdt_k = np.zeros((batch_size, *sdt_shape, nb_labels_sample))\n",
    "        atl_dt_k = np.zeros((batch_size, *sdt_shape, nb_labels_sample))\n",
    "        subj_surface_pts = np.zeros((batch_size, nb_surface_pts, len(vol_shape) + 1))\n",
    "        if nb_labels_sample != len(labels):\n",
    "            atlas_surface_pts = np.zeros((batch_size, nb_surface_pts, len(vol_shape) + 1))\n",
    "\n",
    "        for li, sli in enumerate(sel_label_idxs):\n",
    "            # get the surface point stack indexes for this element\n",
    "            srf_idx = slice(int(np.sum(nb_surface_pts_sel[:li])), int(np.sum(nb_surface_pts_sel[:li+1])))\n",
    "\n",
    "            # get atlas surface points for this label\n",
    "            if nb_labels_sample != len(labels):\n",
    "                atlas_surface_pts_ = std_to_surf(atlas_sdt[sli], nb_surface_pts_sel[li])[np.newaxis, ...]\n",
    "                atlas_surface_pts[:, srf_idx, :-1] = np.repeat(atlas_surface_pts_, batch_size, 0)\n",
    "                atlas_surface_pts[:, srf_idx,  -1] = sli\n",
    "\n",
    "            # compute X distance from surface\n",
    "            X_label = X_seg == labels[sli]\n",
    "            X_label = py.utils.clean_seg_batch(X_label, smooth_seg_std)\n",
    "            X_sdt_k[..., li] = py.utils.vol_to_sdt_batch(X_label, sdt=True, sdt_vol_resize=sdt_vol_resize)[..., 0]\n",
    "\n",
    "            if surf_bidir:\n",
    "                atl_dt = atlas_sdt[li][np.newaxis, ...]\n",
    "                atl_dt_k[..., li] = np.repeat(atl_dt, batch_size, 0)\n",
    "                ssp_lst = [std_to_surf(f[...], nb_surface_pts_sel[li]) for f in X_sdt_k[..., li]]\n",
    "                subj_surface_pts[:, srf_idx, :-1] = np.stack(ssp_lst, 0)\n",
    "                subj_surface_pts[:, srf_idx,  -1] = li\n",
    "\n",
    "        # check if returning segmentations instead of images\n",
    "        # this is a bit hacky for basically building a segmentation-only network (no images)\n",
    "        X_ret = X_img\n",
    "        atlas_ret = atlas_vol_bs\n",
    "\n",
    "        if align_segs:\n",
    "            assert len(labels) == 1, 'align_seg generator is only implemented for single label'\n",
    "            X_ret = X_seg == labels[0]\n",
    "            atlas_ret = atlas_seg_bs == labels[0]\n",
    "\n",
    "        # finally, output\n",
    "        if surf_bidir:\n",
    "            inputs  = [X_ret, atlas_ret, X_sdt_k, atl_dt_k, subj_surface_pts, atlas_surface_pts]\n",
    "            outputs = [atlas_ret, X_ret, zero_flow, zero_surface_values, zero_surface_values]\n",
    "        else:\n",
    "            inputs  = [X_ret, atlas_ret, X_sdt_k, atlas_surface_pts]\n",
    "            outputs = [atlas_ret, X_ret, zero_flow, zero_surface_values]\n",
    "\n",
    "        yield (inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "py.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     1,
     9,
     17,
     69,
     95,
     128,
     143,
     154,
     167,
     177,
     190,
     209,
     223,
     233,
     241,
     262,
     281,
     294,
     303,
     319,
     339
    ]
   },
   "outputs": [],
   "source": [
    "#py.utils\n",
    "def default_unet_features():\n",
    "    nb_features = [\n",
    "        [16, 32, 32, 32],             # encoder\n",
    "        [32, 32, 32, 32, 32, 16, 16]  # decoder\n",
    "    ]\n",
    "    return nb_features\n",
    "\n",
    "\n",
    "def get_backend():\n",
    "    \"\"\"\n",
    "    Returns the currently used backend. Default is tensorflow unless the\n",
    "    VXM_BACKEND environment variable is set to 'pytorch'.\n",
    "    \"\"\"\n",
    "    return 'pytorch' if os.environ.get('VXM_BACKEND') == 'pytorch' else 'tensorflow'\n",
    "\n",
    "\n",
    "def load_volfile(\n",
    "        filename,\n",
    "        np_var='vol',\n",
    "        add_batch_axis=False,\n",
    "        add_feat_axis=False,\n",
    "        pad_shape=None,\n",
    "        resize_factor=1,\n",
    "        ret_affine=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Loads a file in nii, nii.gz, mgz, npz, or npy format.\n",
    "\n",
    "    Parameters:\n",
    "        filename: Filename to load.\n",
    "        np_var: If the file is a npz (compressed numpy) with multiple variables,\n",
    "            the desired variable can be specified with np_var. Default is 'vol'.\n",
    "        add_batch_axis: Adds an axis to the beginning of the array. Default is False.\n",
    "        add_feat_axis: Adds an axis to the end of the array. Default is False.\n",
    "        pad_shape: Zero-pad the array to a target shape. Default is None.\n",
    "        resize: Volume resize factor. Default is 1\n",
    "        ret_affine: Additionally returns the affine transform (or None if it doesn't exist).\n",
    "    \"\"\"\n",
    "    if filename.endswith(('.nii', '.nii.gz', '.mgz')):\n",
    "        import nibabel as nib\n",
    "        img = nib.load(filename)\n",
    "        vol = img.get_data().squeeze()\n",
    "        affine = img.affine\n",
    "    elif filename.endswith('.npy'):\n",
    "        vol = np.load(filename)\n",
    "        affine = None\n",
    "    elif filename.endswith('.npz'):\n",
    "        npz = np.load(filename)\n",
    "        vol = next(iter(npz.values())) if len(npz.keys()) == 1 else npz[np_var]\n",
    "        affine = None\n",
    "    else:\n",
    "        raise ValueError('unknown filetype for %s' % filename)\n",
    "\n",
    "    if pad_shape:\n",
    "        vol, _ = pad(vol, pad_shape)\n",
    "\n",
    "    if add_feat_axis:\n",
    "        vol = vol[..., np.newaxis]\n",
    "\n",
    "    if resize_factor != 1:\n",
    "        vol = resize(vol, resize_factor)\n",
    "\n",
    "    if add_batch_axis:\n",
    "        vol = vol[np.newaxis, ...]\n",
    "\n",
    "    return (vol, affine) if ret_affine else vol\n",
    "\n",
    "\n",
    "def save_volfile(array, filename, affine=None):\n",
    "    \"\"\"\n",
    "    Saves an array to nii, nii.gz, or npz format.\n",
    "\n",
    "    Parameters:\n",
    "        array: The array to save.\n",
    "        filename: Filename to save to.\n",
    "        affine: Affine vox-to-ras matrix. Saves LIA matrix if None (default).\n",
    "    \"\"\"\n",
    "    if filename.endswith(('.nii', '.nii.gz')):\n",
    "        import nibabel as nib\n",
    "        if affine is None and array.ndim >= 3:\n",
    "            # use LIA transform as default affine\n",
    "            affine = np.array([[-1,  0,  0,  0],\n",
    "                               [ 0,  0,  1,  0],\n",
    "                               [ 0, -1,  0,  0],\n",
    "                               [ 0,  0,  0,  1]], dtype=float)\n",
    "            pcrs = np.append(np.array(array.shape[:3]) / 2, 1)\n",
    "            affine[:3, 3] = -np.matmul(affine, pcrs)[:3]\n",
    "        nib.save(nib.Nifti1Image(array, affine), filename)\n",
    "    elif filename.endswith('.npz'):\n",
    "        np.savez_compressed(filename, vol=array)\n",
    "    else:\n",
    "        raise ValueError('unknown filetype for %s' % filename)\n",
    "\n",
    "\n",
    "def load_pheno_csv(filename, training_files=None):\n",
    "    \"\"\"\n",
    "    Loads an attribute csv file into a dictionary. Each line in the csv should represent\n",
    "    attributes for a single training file and should be formatted as:\n",
    "\n",
    "    filename,attr1,attr2,attr2...\n",
    "\n",
    "    Where filename is the file basename and each attr is a floating point number. If\n",
    "    a list of training_files is specified, the dictionary file keys will be updated\n",
    "    to match the paths specified in the list. Any training files not found in the\n",
    "    loaded dictionary are pruned.\n",
    "    \"\"\"\n",
    "\n",
    "    # load csv into dictionary\n",
    "    pheno = {}\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        header = next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            pheno[row[0]] = np.array([float(f) for f in row[1:]])\n",
    "\n",
    "    # make list of valid training files\n",
    "    if training_files is None:\n",
    "        training_files = list(training_files.keys())\n",
    "    else:\n",
    "        training_files = [f for f in training_files if os.path.basename(f) in pheno.keys()]\n",
    "        # make sure pheno dictionary includes the correct path to training data\n",
    "        for f in training_files:\n",
    "            pheno[f] = pheno[os.path.basename(f)]\n",
    "\n",
    "    return pheno, training_files\n",
    "\n",
    "\n",
    "def pad(array, shape):\n",
    "    \"\"\"\n",
    "    Zero-pads an array to a given shape. Returns the padded array and crop slices.\n",
    "    \"\"\"\n",
    "    if array.shape == tuple(shape):\n",
    "        return array, ...\n",
    "\n",
    "    padded = np.zeros(shape, dtype=array.dtype)\n",
    "    offsets = [int((p - v) / 2) for p, v in zip(shape, array.shape)]\n",
    "    slices = tuple([slice(offset, l + offset) for offset, l in zip(offsets, array.shape)])\n",
    "    padded[slices] = array\n",
    "\n",
    "    return padded, slices\n",
    "\n",
    "\n",
    "def resize(array, factor):\n",
    "    \"\"\"\n",
    "    Resizes an array by a given factor. This expects the input array to include a feature dimension.\n",
    "    \"\"\"\n",
    "    if factor == 1:\n",
    "        return array\n",
    "    else:\n",
    "        dim_factors = [factor for _ in array.shape[:-1]] + [1]\n",
    "        return scipy.ndimage.interpolation.zoom(array, dim_factors, order=0)\n",
    "\n",
    "\n",
    "def dice(array1, array2, labels):\n",
    "    \"\"\"\n",
    "    Computes the dice overlap between two arrays for a given set of integer labels.\n",
    "    \"\"\"\n",
    "    dicem = np.zeros(len(labels))\n",
    "    for idx, label in enumerate(labels):\n",
    "        top = 2 * np.sum(np.logical_and(array1 == label, array2 == label))\n",
    "        bottom = np.sum(array1 == label) + np.sum(array2 == label)\n",
    "        bottom = np.maximum(bottom, np.finfo(float).eps)  # add epsilon\n",
    "        dicem[idx] = top / bottom\n",
    "    return dicem\n",
    "\n",
    "\n",
    "def affine_shift_to_matrix(trf, resize=None):\n",
    "    \"\"\"\n",
    "    Converts an affine shift to a matrix (over the identity).\n",
    "    \"\"\"\n",
    "    matrix = np.concatenate([trf.reshape((3, 4)), np.zeros((1, 4))], 0) + np.eye(4)\n",
    "    if resize is not None:\n",
    "        matrix[:3, -1] *= resize\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def extract_largest_vol(bw, connectivity=1):\n",
    "    \"\"\"\n",
    "    Extracts the binary (boolean) image with just the largest component.\n",
    "    TODO: This might be less than efficiently implemented.\n",
    "    \"\"\"\n",
    "    lab = measure.label(bw.astype('int'), connectivity=connectivity)\n",
    "    regions = measure.regionprops(lab, cache=False)\n",
    "    areas = [f.area for f in regions]\n",
    "    ai = np.argsort(areas)[::-1]\n",
    "    bw = lab == ai[0] + 1\n",
    "    return bw\n",
    "\n",
    "\n",
    "def clean_seg(x, std=1):\n",
    "    \"\"\"\n",
    "    Cleans a segmentation image.\n",
    "    \"\"\"\n",
    "\n",
    "    # take out islands, fill in holes, and gaussian blur\n",
    "    bw = extract_largest_vol(x)\n",
    "    bw = 1 - extract_largest_vol(1 - bw)\n",
    "    gadt = scipy.ndimage.gaussian_filter(bw.astype('float'), std)\n",
    "\n",
    "    # figure out the proper threshold to maintain the total volume\n",
    "    sgadt = np.sort(gadt.flatten())[::-1]\n",
    "    thr = sgadt[np.ceil(bw.sum()).astype(int)]\n",
    "    clean_bw = gadt > thr\n",
    "\n",
    "    assert np.isclose(bw.sum(), clean_bw.sum(), atol=5), 'cleaning segmentation failed'\n",
    "    return clean_bw.astype(float)\n",
    "\n",
    "\n",
    "def clean_seg_batch(X_label, std=1):\n",
    "    \"\"\"\n",
    "    Cleans batches of segmentation images.\n",
    "    \"\"\"\n",
    "    if not X_label.dtype == 'float':\n",
    "        X_label = X_label.astype('float')\n",
    "\n",
    "    data = np.zeros(X_label.shape)\n",
    "    for xi, x in enumerate(X_label):\n",
    "        data[xi,...,0] = clean_seg(x[...,0], std)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def filter_labels(atlas_vol, labels):\n",
    "    \"\"\"\n",
    "    Filters given volumes to only include given labels, all other voxels are set to 0.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(atlas_vol.shape, 'bool')\n",
    "    for label in labels:\n",
    "        mask = np.logical_or(mask, atlas_vol == label)\n",
    "    return atlas_vol * mask\n",
    "\n",
    "\n",
    "def dist_trf(bwvol):\n",
    "    \"\"\"\n",
    "    Computes positive distance transform from positive entries in a logical image.\n",
    "    \"\"\"\n",
    "    revbwvol = np.logical_not(bwvol)\n",
    "    return scipy.ndimage.morphology.distance_transform_edt(revbwvol)\n",
    "\n",
    "\n",
    "def signed_dist_trf(bwvol):\n",
    "    \"\"\"\n",
    "    Computes the signed distance transform from the surface between the binary\n",
    "    elements of an image\n",
    "    NOTE: The distance transform on either side of the surface will be +/- 1,\n",
    "    so there are no voxels for which the distance should be 0.\n",
    "    NOTE: Currently the function uses bwdist twice. If there is a quick way to\n",
    "    compute the surface, bwdist could be used only once.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the positive transform (outside the positive island)\n",
    "    posdst = dist_trf(bwvol)\n",
    "\n",
    "    # get the negative transform (distance inside the island)\n",
    "    notbwvol = np.logical_not(bwvol)\n",
    "    negdst = dist_trf(notbwvol)\n",
    "\n",
    "    # combine the positive and negative map\n",
    "    return posdst * notbwvol - negdst * bwvol\n",
    "\n",
    "\n",
    "def vol_to_sdt(X_label, sdt=True, sdt_vol_resize=1):\n",
    "    \"\"\"\n",
    "    Computes the signed distance transform from a volume.\n",
    "    \"\"\"\n",
    "\n",
    "    X_dt = signed_dist_trf(X_label)\n",
    "    \n",
    "    if not (sdt_vol_resize == 1):\n",
    "        if not isinstance(sdt_vol_resize, (list, tuple)):\n",
    "            sdt_vol_resize = [sdt_vol_resize] * X_dt.ndim\n",
    "        if any([f != 1 for f in sdt_vol_resize]):\n",
    "            X_dt = scipy.ndimage.interpolation.zoom(X_dt, sdt_vol_resize, order=1, mode='reflect')\n",
    "    \n",
    "    if not sdt:\n",
    "        X_dt = np.abs(X_dt)\n",
    "    \n",
    "    return X_dt\n",
    "\n",
    "\n",
    "def vol_to_sdt_batch(X_label, sdt=True, sdt_vol_resize=1):\n",
    "    \"\"\"\n",
    "    Computes the signed distance transforms from volume batches.\n",
    "    \"\"\"\n",
    "\n",
    "    # assume X_label is [batch_size, *vol_shape, 1]\n",
    "    assert X_label.shape[-1] == 1, 'implemented assuming size is [batch_size, *vol_shape, 1]'\n",
    "    X_lst = [f[...,0] for f in X_label]  # get rows\n",
    "    X_dt_lst = [vol_to_sdt(f, sdt=sdt, sdt_vol_resize=sdt_vol_resize) for f in X_lst]  # distance transform\n",
    "    X_dt = np.stack(X_dt_lst, 0)[..., np.newaxis]\n",
    "    return X_dt\n",
    "\n",
    "\n",
    "def get_surface_pts_per_label(total_nb_surface_pts, layer_edge_ratios):\n",
    "    \"\"\"\n",
    "    Gets the number of surface points per label, given the total number of surface points.\n",
    "    \"\"\"\n",
    "    nb_surface_pts_sel = np.round(np.array(layer_edge_ratios) * total_nb_surface_pts).astype('int')\n",
    "    nb_surface_pts_sel[-1] = total_nb_surface_pts - int(np.sum(nb_surface_pts_sel[:-1]))\n",
    "    return nb_surface_pts_sel\n",
    "\n",
    "\n",
    "def edge_to_surface_pts(X_edges, nb_surface_pts=None):\n",
    "    \"\"\"\n",
    "    Converts edges to surface points.\n",
    "    \"\"\"\n",
    "\n",
    "    # assumes X_edges is NOT in keras form\n",
    "    surface_pts = np.stack(np.where(X_edges), 0).transpose()\n",
    "    \n",
    "    # random with replacements\n",
    "    if nb_surface_pts is not None:\n",
    "        chi = np.random.choice(range(surface_pts.shape[0]), size=nb_surface_pts)\n",
    "        surface_pts = surface_pts[chi,:]\n",
    "\n",
    "    return surface_pts\n",
    "\n",
    "\n",
    "def sdt_to_surface_pts(X_sdt, nb_surface_pts, surface_pts_upsample_factor=2, thr=0.50001, resize_fn=None):\n",
    "    \"\"\"\n",
    "    Converts a signed distance transform to surface points.\n",
    "    \"\"\"\n",
    "    us = [surface_pts_upsample_factor] * X_sdt.ndim\n",
    "    \n",
    "    if resize_fn is None:\n",
    "        resized_vol = scipy.ndimage.interpolation.zoom(X_sdt, us, order=1, mode='reflect')\n",
    "    else:\n",
    "        resized_vol = resize_fn(X_sdt)\n",
    "        pred_shape = np.array(X_sdt.shape)*surface_pts_upsample_factor\n",
    "        assert np.array_equal(pred_shape, resized_vol.shape), 'resizing failed'\n",
    "\n",
    "    X_edges = np.abs(resized_vol) < thr\n",
    "    sf_pts = edge_to_surface_pts(X_edges, nb_surface_pts=nb_surface_pts)\n",
    "\n",
    "    # can't just correct by surface_pts_upsample_factor because of how interpolation works...\n",
    "    return np.stack([sf_pts[..., f] * (X_sdt.shape[f] - 1) / (X_edges.shape[f] - 1) for f in range(X_sdt.ndim)], -1)\n",
    "\n",
    "\n",
    "def jacobian_determinant(disp):\n",
    "    \"\"\"\n",
    "    jacobian determinant of a displacement field.\n",
    "    NB: to compute the spatial gradients, we use np.gradient.\n",
    "\n",
    "    Parameters:\n",
    "        disp: 2D or 3D displacement field of size [*vol_shape, nb_dims], \n",
    "              where vol_shape is of len nb_dims\n",
    "\n",
    "    Returns:\n",
    "        jacobian determinant (scalar)\n",
    "    \"\"\"\n",
    "\n",
    "    # check inputs\n",
    "    volshape = disp.shape[:-1]\n",
    "    nb_dims = len(volshape)\n",
    "    assert len(volshape) in (2, 3), 'flow has to be 2D or 3D'\n",
    "\n",
    "    # compute grid\n",
    "    grid_lst = nd.volsize2ndgrid(volshape)\n",
    "    grid = np.stack(grid_lst, len(volshape))\n",
    "\n",
    "    # compute gradients\n",
    "    J = np.gradient(disp + grid)\n",
    "\n",
    "    # 3D glow\n",
    "    if nb_dims == 3:\n",
    "        dx = J[0]\n",
    "        dy = J[1]\n",
    "        dz = J[2]\n",
    "\n",
    "        # compute jacobian components\n",
    "        Jdet0 = dx[..., 0] * (dy[..., 1] * dz[..., 2] - dy[..., 2] * dz[..., 1])\n",
    "        Jdet1 = dx[..., 1] * (dy[..., 0] * dz[..., 2] - dy[..., 2] * dz[..., 0])\n",
    "        Jdet2 = dx[..., 2] * (dy[..., 0] * dz[..., 1] - dy[..., 1] * dz[..., 0])\n",
    "\n",
    "        return Jdet0 - Jdet1 + Jdet2\n",
    "\n",
    "    else: # must be 2 \n",
    "        \n",
    "        dfdx = J[0]\n",
    "        dfdy = J[1] \n",
    "        \n",
    "        return dfdx[..., 0] * dfdy[..., 1] - dfdy[..., 0] * dfdx[..., 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     3,
     34
    ]
   },
   "outputs": [],
   "source": [
    "#modelio\n",
    "\n",
    "\n",
    "def store_config_args(func):\n",
    "    \"\"\"\n",
    "    Class-method decorator that saves every argument provided to the\n",
    "    function as a dictionary in 'self.config'. This is used to assist\n",
    "    model loading - see LoadableModel.\n",
    "    \"\"\"\n",
    "\n",
    "    attrs, varargs, varkw, defaults = inspect.getargspec(func)\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        self.config = {}\n",
    "\n",
    "        # first save the default values\n",
    "        if defaults:\n",
    "            for attr, val in zip(reversed(attrs), reversed(defaults)):\n",
    "                self.config[attr] = val\n",
    "\n",
    "        # next handle positional args\n",
    "        for attr, val in zip(attrs[1:], args):\n",
    "            self.config[attr] = val\n",
    "\n",
    "        # lastly handle keyword args\n",
    "        if kwargs:\n",
    "            for attr, val in kwargs.items():\n",
    "                self.config[attr] = val\n",
    "\n",
    "        return func(self, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class LoadableModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for easy pytorch model loading without having to manually\n",
    "    specify the architecture configuration at load time.\n",
    "\n",
    "    We can cache the arguments used to the construct the initial network, so that\n",
    "    we can construct the exact same network when loading from file. The arguments\n",
    "    provided to __init__ are automatically saved into the object (in self.config)\n",
    "    if the __init__ method is decorated with the @store_config_args utility.\n",
    "    \"\"\"\n",
    "\n",
    "    # this constructor just functions as a check to make sure that every\n",
    "    # LoadableModel subclass has provided an internal config parameter\n",
    "    # either manually or via store_config_args\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if not hasattr(self, 'config'):\n",
    "            raise RuntimeError('models that inherit from LoadableModel must decorate the constructor with @store_config_args')\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"\n",
    "        Saves the model configuration and weights to a pytorch file.\n",
    "        \"\"\"\n",
    "        # don't save the transformer_grid buffers - see SpatialTransformer doc for more info\n",
    "        sd = self.state_dict().copy()\n",
    "        grid_buffers = [key for key in sd.keys() if key.endswith('.grid')]\n",
    "        for key in grid_buffers:\n",
    "            sd.pop(key)\n",
    "        torch.save({'config': self.config, 'model_state': sd}, path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path, device):\n",
    "        \"\"\"\n",
    "        Load a python model configuration and weights.\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(path, map_location=torch.device(device))\n",
    "        model = cls(**checkpoint['config'])\n",
    "        model.load_state_dict(checkpoint['model_state'], strict=False)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     1,
     88,
     207
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l:\\anaconda3\\envs\\cs286\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#Network\n",
    "class Unet(nn.Module):\n",
    "    \"\"\"\n",
    "    A unet architecture. Layer features can be specified directly as a list of encoder and decoder\n",
    "    features or as a single integer along with a number of unet levels. The default network features\n",
    "    per layer (when no options are specified) are:\n",
    "\n",
    "        encoder: [16, 32, 32, 32]\n",
    "        decoder: [32, 32, 32, 32, 32, 16, 16]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inshape, nb_features=None, nb_levels=None, feat_mult=1):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            inshape: Input shape. e.g. (192, 192, 192)\n",
    "            nb_features: Unet convolutional features. Can be specified via a list of lists with\n",
    "                the form [[encoder feats], [decoder feats]], or as a single integer. If None (default),\n",
    "                the unet features are defined by the default config described in the class documentation.\n",
    "            nb_levels: Number of levels in unet. Only used when nb_features is an integer. Default is None.\n",
    "            feat_mult: Per-level feature multiplier. Only used when nb_features is an integer. Default is 1.\n",
    "        \"\"\"\n",
    "\n",
    "        # ensure correct dimensionality\n",
    "        ndims = len(inshape)\n",
    "        assert ndims in [1, 2, 3], 'ndims should be one of 1, 2, or 3. found: %d' % ndims\n",
    "\n",
    "        # default encoder and decoder layer features if nothing provided\n",
    "        if nb_features is None:\n",
    "            nb_features = default_unet_features()\n",
    "\n",
    "        # build feature list automatically\n",
    "        if isinstance(nb_features, int):\n",
    "            if nb_levels is None:\n",
    "                raise ValueError('must provide unet nb_levels if nb_features is an integer')\n",
    "            feats = np.round(nb_features * feat_mult ** np.arange(nb_levels)).astype(int)\n",
    "            self.enc_nf = feats[:-1]\n",
    "            self.dec_nf = np.flip(feats)\n",
    "        elif nb_levels is not None:\n",
    "            raise ValueError('cannot use nb_levels if nb_features is not an integer')\n",
    "        else:\n",
    "            self.enc_nf, self.dec_nf = nb_features\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        # configure encoder (down-sampling path)\n",
    "        prev_nf = 2\n",
    "        self.downarm = nn.ModuleList()\n",
    "        for nf in self.enc_nf:\n",
    "            self.downarm.append(ConvBlock(ndims, prev_nf, nf, stride=2))\n",
    "            prev_nf = nf\n",
    "\n",
    "        # configure decoder (up-sampling path)\n",
    "        enc_history = list(reversed(self.enc_nf))\n",
    "        self.uparm = nn.ModuleList()\n",
    "        for i, nf in enumerate(self.dec_nf[:len(self.enc_nf)]):\n",
    "            channels = prev_nf + enc_history[i] if i > 0 else prev_nf\n",
    "            self.uparm.append(ConvBlock(ndims, channels, nf, stride=1))\n",
    "            prev_nf = nf\n",
    "\n",
    "        # configure extra decoder convolutions (no up-sampling)\n",
    "        prev_nf += 2\n",
    "        self.extras = nn.ModuleList()\n",
    "        for nf in self.dec_nf[len(self.enc_nf):]:\n",
    "            self.extras.append(ConvBlock(ndims, prev_nf, nf, stride=1))\n",
    "            prev_nf = nf\n",
    " \n",
    "    def forward(self, x):\n",
    "\n",
    "        # get encoder activations\n",
    "        x_enc = [x]\n",
    "        for layer in self.downarm:\n",
    "            x_enc.append(layer(x_enc[-1]))\n",
    "\n",
    "        # conv, upsample, concatenate series\n",
    "        x = x_enc.pop()\n",
    "        for layer in self.uparm:\n",
    "            x = layer(x)\n",
    "            x = self.upsample(x)\n",
    "            x = torch.cat([x, x_enc.pop()], dim=1)\n",
    "\n",
    "        # extra convs at full resolution\n",
    "        for layer in self.extras:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class VxmDense(LoadableModel):\n",
    "    \"\"\"\n",
    "    VoxelMorph network for (unsupervised) nonlinear registration between two images.\n",
    "    \"\"\"\n",
    "\n",
    "    @store_config_args\n",
    "    def __init__(self,\n",
    "        inshape,\n",
    "        nb_unet_features=None,\n",
    "        nb_unet_levels=None,\n",
    "        unet_feat_mult=1,\n",
    "        int_steps=7,\n",
    "        int_downsize=2,\n",
    "        bidir=False,\n",
    "        use_probs=False):\n",
    "        \"\"\" \n",
    "        Parameters:\n",
    "            inshape: Input shape. e.g. (192, 192, 192)\n",
    "            nb_unet_features: Unet convolutional features. Can be specified via a list of lists with\n",
    "                the form [[encoder feats], [decoder feats]], or as a single integer. If None (default),\n",
    "                the unet features are defined by the default config described in the unet class documentation.\n",
    "            nb_unet_levels: Number of levels in unet. Only used when nb_features is an integer. Default is None.\n",
    "            unet_feat_mult: Per-level feature multiplier. Only used when nb_features is an integer. Default is 1.\n",
    "            int_steps: Number of flow integration steps. The warp is non-diffeomorphic when this value is 0.\n",
    "            int_downsize: Integer specifying the flow downsample factor for vector integration. The flow field\n",
    "                is not downsampled when this value is 1.\n",
    "            bidir: Enable bidirectional cost function. Default is False.\n",
    "            use_probs: Use probabilities in flow field. Default is False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # internal flag indicating whether to return flow or integrated warp during inference\n",
    "        self.training = True\n",
    "\n",
    "        # ensure correct dimensionality\n",
    "        ndims = len(inshape)\n",
    "        assert ndims in [1, 2, 3], 'ndims should be one of 1, 2, or 3. found: %d' % ndims\n",
    "\n",
    "        # configure core unet model\n",
    "        self.unet_model = Unet(\n",
    "            inshape,\n",
    "            nb_features=nb_unet_features,\n",
    "            nb_levels=nb_unet_levels,\n",
    "            feat_mult=unet_feat_mult\n",
    "        )\n",
    "\n",
    "        # configure unet to flow field layer\n",
    "        Conv = getattr(nn, 'Conv%dd' % ndims)\n",
    "        self.flow = Conv(self.unet_model.dec_nf[-1], ndims, kernel_size=3, padding=1)\n",
    "\n",
    "        # init flow layer with small weights and bias\n",
    "        self.flow.weight = nn.Parameter(Normal(0, 1e-5).sample(self.flow.weight.shape))\n",
    "        self.flow.bias = nn.Parameter(torch.zeros(self.flow.bias.shape))\n",
    "\n",
    "        # probabilities are not supported in pytorch\n",
    "        if use_probs:\n",
    "            raise NotImplementedError('Flow variance has not been implemented in pytorch - set use_probs to False')\n",
    "\n",
    "        # configure optional resize layers\n",
    "        resize = int_steps > 0 and int_downsize > 1\n",
    "        self.resize = ResizeTransform(int_downsize, ndims) if resize else None\n",
    "        self.fullsize = ResizeTransform(1 / int_downsize, ndims) if resize else None\n",
    "\n",
    "        # configure bidirectional training\n",
    "        self.bidir = bidir\n",
    "\n",
    "        # configure optional integration layer for diffeomorphic warp\n",
    "        down_shape = [int(dim / int_downsize) for dim in inshape]\n",
    "        self.integrate = VecInt(down_shape, int_steps) if int_steps > 0 else None\n",
    "\n",
    "        # configure transformer\n",
    "        self.transformer = SpatialTransformer(inshape)\n",
    "\n",
    "    def forward(self, source, target, registration=False):\n",
    "        '''\n",
    "        Parameters:\n",
    "            source: Source image tensor.\n",
    "            target: Target image tensor.\n",
    "            registration: Return transformed image and flow. Default is False.\n",
    "        '''\n",
    "\n",
    "        # concatenate inputs and propagate unet\n",
    "        x = torch.cat([source, target], dim=1)\n",
    "        x = self.unet_model(x)\n",
    "\n",
    "        # transform into flow field\n",
    "        flow_field = self.flow(x)\n",
    "\n",
    "        # resize flow for integration\n",
    "        pos_flow = flow_field\n",
    "        if self.resize:\n",
    "            pos_flow = self.resize(pos_flow)\n",
    "\n",
    "        preint_flow = pos_flow\n",
    "\n",
    "        # negate flow for bidirectional model\n",
    "        neg_flow = -pos_flow if self.bidir else None\n",
    "\n",
    "        # integrate to produce diffeomorphic warp\n",
    "        if self.integrate:\n",
    "            pos_flow = self.integrate(pos_flow)\n",
    "            neg_flow = self.integrate(neg_flow) if self.bidir else None\n",
    "\n",
    "            # resize to final resolution\n",
    "            if self.fullsize:\n",
    "                pos_flow = self.fullsize(pos_flow)\n",
    "                neg_flow = self.fullsize(neg_flow) if self.bidir else None\n",
    "\n",
    "        # warp image with flow field\n",
    "        y_source = self.transformer(source, pos_flow)\n",
    "        y_target = self.transformer(target, neg_flow) if self.bidir else None\n",
    "\n",
    "        # return non-integrated flow field if training\n",
    "        if not registration:\n",
    "            return (y_source, y_target, preint_flow) if self.bidir else (y_source, preint_flow)\n",
    "        else:\n",
    "            return y_source, pos_flow\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Specific convolutional block followed by leakyrelu for unet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ndims, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        Conv = getattr(nn, 'Conv%dd' % ndims)\n",
    "        self.main = Conv(in_channels, out_channels, 3, stride, 1)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        out = self.activation(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     1,
     46,
     66
    ]
   },
   "outputs": [],
   "source": [
    "#layers\n",
    "class SpatialTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    N-D Spatial Transformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, mode='bilinear'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        # create sampling grid\n",
    "        vectors = [torch.arange(0, s) for s in size]\n",
    "        grids = torch.meshgrid(vectors)\n",
    "        grid = torch.stack(grids)\n",
    "        grid = torch.unsqueeze(grid, 0)\n",
    "        grid = grid.type(torch.FloatTensor)\n",
    "\n",
    "        # registering the grid as a buffer cleanly moves it to the GPU, but it also\n",
    "        # adds it to the state dict. this is annoying since everything in the state dict\n",
    "        # is included when saving weights to disk, so the model files are way bigger\n",
    "        # than they need to be. so far, there does not appear to be an elegant solution.\n",
    "        # see: https://discuss.pytorch.org/t/how-to-register-buffer-without-polluting-state-dict\n",
    "        self.register_buffer('grid', grid)\n",
    "\n",
    "    def forward(self, src, flow):\n",
    "        # new locations\n",
    "        new_locs = self.grid + flow\n",
    "        shape = flow.shape[2:]\n",
    "\n",
    "        # need to normalize grid values to [-1, 1] for resampler\n",
    "        for i in range(len(shape)):\n",
    "            new_locs[:, i, ...] = 2 * (new_locs[:, i, ...] / (shape[i] - 1) - 0.5)\n",
    "\n",
    "        # move channels dim to last position\n",
    "        # also not sure why, but the channels need to be reversed\n",
    "        if len(shape) == 2:\n",
    "            new_locs = new_locs.permute(0, 2, 3, 1)\n",
    "            new_locs = new_locs[..., [1, 0]]\n",
    "        elif len(shape) == 3:\n",
    "            new_locs = new_locs.permute(0, 2, 3, 4, 1)\n",
    "            new_locs = new_locs[..., [2, 1, 0]]\n",
    "\n",
    "        return nnf.grid_sample(src, new_locs, align_corners=True, mode=self.mode)\n",
    "\n",
    "\n",
    "class VecInt(nn.Module):\n",
    "    \"\"\"\n",
    "    Integrates a vector field via scaling and squaring.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inshape, nsteps):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert nsteps >= 0, 'nsteps should be >= 0, found: %d' % nsteps\n",
    "        self.nsteps = nsteps\n",
    "        self.scale = 1.0 / (2 ** self.nsteps)\n",
    "        self.transformer = SpatialTransformer(inshape)\n",
    "\n",
    "    def forward(self, vec):\n",
    "        vec = vec * self.scale\n",
    "        for _ in range(self.nsteps):\n",
    "            vec = vec + self.transformer(vec, vec)\n",
    "        return vec\n",
    "\n",
    "\n",
    "class ResizeTransform(nn.Module):\n",
    "    \"\"\"\n",
    "    Resize a transform, which involves resizing the vector field *and* rescaling it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vel_resize, ndims):\n",
    "        super().__init__()\n",
    "        self.factor = 1.0 / vel_resize\n",
    "        self.mode = 'linear'\n",
    "        if ndims == 2:\n",
    "            self.mode = 'bi' + self.mode\n",
    "        elif ndims == 3:\n",
    "            self.mode = 'tri' + self.mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.factor < 1:\n",
    "            # resize first to save memory\n",
    "            x = nnf.interpolate(x, align_corners=True, scale_factor=self.factor, mode=self.mode)\n",
    "            x = self.factor * x\n",
    "\n",
    "        elif self.factor > 1:\n",
    "            # multiply first to save memory\n",
    "            x = self.factor * x\n",
    "            x = nnf.interpolate(x, align_corners=True, scale_factor=self.factor, mode=self.mode)\n",
    "\n",
    "        # don't do anything if resize is 1\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     2,
     65,
     74,
     88
    ]
   },
   "outputs": [],
   "source": [
    "#losses\n",
    "\n",
    "class NCC:\n",
    "    \"\"\"\n",
    "    Local (over window) normalized cross correlation loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, win=None):\n",
    "        self.win = win\n",
    "\n",
    "    def loss(self, y_true, y_pred):\n",
    "\n",
    "        I = y_true\n",
    "        J = y_pred\n",
    "\n",
    "        # get dimension of volume\n",
    "        # assumes I, J are sized [batch_size, *vol_shape, nb_feats]\n",
    "        ndims = len(list(I.size())) - 2\n",
    "        assert ndims in [1, 2, 3], \"volumes should be 1 to 3 dimensions. found: %d\" % ndims\n",
    "\n",
    "        # set window size\n",
    "        win = [9] * ndims if self.win is None else self.win\n",
    "\n",
    "        # compute filters\n",
    "        sum_filt = torch.ones([1, 1, *win]).to(\"cuda\")\n",
    "\n",
    "        pad_no = math.floor(win[0]/2)\n",
    "\n",
    "        if ndims == 1:\n",
    "            stride = (1)\n",
    "            padding = (pad_no)\n",
    "        elif ndims == 2:\n",
    "            stride = (1,1)\n",
    "            padding = (pad_no, pad_no)\n",
    "        else:\n",
    "            stride = (1,1,1)\n",
    "            padding = (pad_no, pad_no, pad_no)\n",
    "\n",
    "        # get convolution function\n",
    "        conv_fn = getattr(nnf, 'conv%dd' % ndims)\n",
    "\n",
    "        # compute CC squares\n",
    "        I2 = I * I\n",
    "        J2 = J * J\n",
    "        IJ = I * J\n",
    "\n",
    "        I_sum = conv_fn(I, sum_filt, stride=stride, padding=padding)\n",
    "        J_sum = conv_fn(J, sum_filt, stride=stride, padding=padding)\n",
    "        I2_sum = conv_fn(I2, sum_filt, stride=stride, padding=padding)\n",
    "        J2_sum = conv_fn(J2, sum_filt, stride=stride, padding=padding)\n",
    "        IJ_sum = conv_fn(IJ, sum_filt, stride=stride, padding=padding)\n",
    "\n",
    "        win_size = np.prod(win)\n",
    "        u_I = I_sum / win_size\n",
    "        u_J = J_sum / win_size\n",
    "\n",
    "        cross = IJ_sum - u_J * I_sum - u_I * J_sum + u_I * u_J * win_size\n",
    "        I_var = I2_sum - 2 * u_I * I_sum + u_I * u_I * win_size\n",
    "        J_var = J2_sum - 2 * u_J * J_sum + u_J * u_J * win_size\n",
    "\n",
    "        cc = cross * cross / (I_var * J_var + 1e-5)\n",
    "\n",
    "        return -torch.mean(cc)\n",
    "\n",
    "\n",
    "class MSE:\n",
    "    \"\"\"\n",
    "    Mean squared error loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def loss(self, y_true, y_pred):\n",
    "        return torch.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "\n",
    "class Dice:\n",
    "    \"\"\"\n",
    "    N-D dice for segmentation\n",
    "    \"\"\"\n",
    "\n",
    "    def loss(self, y_true, y_pred):\n",
    "        ndims = len(list(y_pred.size())) - 2\n",
    "        vol_axes = list(range(2, ndims+2))\n",
    "        top = 2 * (y_true * y_pred).sum(dim=vol_axes)\n",
    "        bottom = torch.clamp((y_true + y_pred).sum(dim=vol_axes), min=1e-5)\n",
    "        dice = torch.mean(top / bottom)\n",
    "        return -dice\n",
    "\n",
    "\n",
    "class Grad:\n",
    "    \"\"\"\n",
    "    N-D gradient loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, penalty='l1', loss_mult=None):\n",
    "        self.penalty = penalty\n",
    "        self.loss_mult = loss_mult\n",
    "\n",
    "    def loss(self, _, y_pred):\n",
    "        dy = torch.abs(y_pred[:, :, 1:, :, :] - y_pred[:, :, :-1, :, :]) \n",
    "        dx = torch.abs(y_pred[:, :, :, 1:, :] - y_pred[:, :, :, :-1, :]) \n",
    "        dz = torch.abs(y_pred[:, :, :, :, 1:] - y_pred[:, :, :, :, :-1]) \n",
    "\n",
    "        if self.penalty == 'l2':\n",
    "            dy = dy * dy\n",
    "            dx = dx * dx\n",
    "            dz = dz * dz\n",
    "\n",
    "        d = torch.mean(dx) + torch.mean(dy) + torch.mean(dz)\n",
    "        grad = d / 3.0\n",
    "\n",
    "        if self.loss_mult is not None:\n",
    "            grad *= self.loss_mult\n",
    "        return grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7ae7db7b6676>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;31m# generate inputs (and true outputs) and convert them to tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-7ae7db7b6676>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;31m# generate inputs (and true outputs) and convert them to tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "#train\n",
    "\n",
    "\"\"\"\n",
    "Example script to train a VoxelMorph model.\n",
    "\n",
    "For the CVPR and MICCAI papers, we have data arranged in train, validate, and test folders. Inside each folder\n",
    "are normalized T1 volumes and segmentations in npz (numpy) format. You will have to customize this script slightly\n",
    "to accommodate your own data. All images should be appropriately cropped and scaled to values between 0 and 1.\n",
    "\n",
    "If an atlas file is provided with the --atlas flag, then scan-to-atlas training is performed. Otherwise,\n",
    "registration will be scan-to-scan.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#设置各种超参\n",
    "datadir='./data/' #数据路径\n",
    "atlasdir='./data/atlas.npz' #模板/地图路径\n",
    "model_dir='./models/' #模型存储路径\n",
    "multichannel=True #是否是多通道图片，还是灰度图\n",
    "gpu='0' #选哪个gpu跑\n",
    "batch_size=1 #批大小\n",
    "epochs=1500 #代数量\n",
    "steps_per_epoch=100 #每个代跑几步\n",
    "load_model='./models/model' #加载的模型的文件\n",
    "initial_epoch=0 #初始epoch数量，我猜是用来检查程序是否正常工作\n",
    "lr=1e-4 #学习率\n",
    "cudnn_nondet=False #是否禁用cudnn\n",
    "enc=[16,32,32,32] #Unet中编码器的层数和结构\n",
    "dec=[32,32,32,32,32,16,16] #解码器的层数和结构\n",
    "int_steps=7 #不知道是啥\n",
    "int_downsize=2 #不知道是啥\n",
    "bidir=False #是否启用双向损失函数\n",
    "image_loss='ncc' #损失函数，用来评估预测结果与输入的相似程度\n",
    "lambda_weight=0.01 #平滑损失占总损失函数中的比例\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # import voxelmorph with pytorch backend\n",
    "# os.environ['VXM_BACKEND'] = 'pytorch'\n",
    "\n",
    "\n",
    "# # parse the commandline\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# # data organization parameters\n",
    "# parser.add_argument('datadir', help='base data directory')\n",
    "# parser.add_argument('--atlas', help='atlas filename (default: data/atlas_norm.npz)')\n",
    "# parser.add_argument('--model-dir', default='models', help='model output directory (default: models)')\n",
    "# parser.add_argument('--multichannel', action='store_true', help='specify that data has multiple channels')\n",
    "\n",
    "# # training parameters\n",
    "# parser.add_argument('--gpu', default='0', help='GPU ID number(s), comma-separated (default: 0)')\n",
    "# parser.add_argument('--batch-size', type=int, default=1, help='batch size (default: 1)')\n",
    "# parser.add_argument('--epochs', type=int, default=1500, help='number of training epochs (default: 1500)')\n",
    "# parser.add_argument('--steps-per-epoch', type=int, default=100, help='frequency of model saves (default: 100)')\n",
    "# parser.add_argument('--load-model', help='optional model file to initialize with')\n",
    "# parser.add_argument('--initial-epoch', type=int, default=0, help='initial epoch number (default: 0)')\n",
    "# parser.add_argument('--lr', type=float, default=1e-4, help='learning rate (default: 1e-4)')\n",
    "# parser.add_argument('--cudnn-nondet',  action='store_true', help='disable cudnn determinism - might slow down training')\n",
    "\n",
    "# # network architecture parameters\n",
    "# parser.add_argument('--enc', type=int, nargs='+', help='list of unet encoder filters (default: 16 32 32 32)')\n",
    "# parser.add_argument('--dec', type=int, nargs='+', help='list of unet decorder filters (default: 32 32 32 32 32 16 16)')\n",
    "# parser.add_argument('--int-steps', type=int, default=7, help='number of integration steps (default: 7)')\n",
    "# parser.add_argument('--int-downsize', type=int, default=2, help='flow downsample factor for integration (default: 2)')\n",
    "# parser.add_argument('--bidir', action='store_true', help='enable bidirectional cost function')\n",
    "\n",
    "# # loss hyperparameters\n",
    "# parser.add_argument('--image-loss', default='mse', help='image reconstruction loss - can be mse or ncc (default: mse)')\n",
    "# parser.add_argument('--lambda', type=float, dest='weight', default=0.01, help='weight of deformation loss (default: 0.01)')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# bidir = args.bidir\n",
    "\n",
    "#读取数据并且打乱\n",
    "# load and prepare training data\n",
    "# train_vol_names = glob.glob(os.path.join(datadir, '*.npz'))\n",
    "train_vol_names = glob.glob(os.path.join(datadir, 'atlas.npz'))\n",
    "# random.shuffle(train_vol_names)  # shuffle volume list\n",
    "assert len(train_vol_names) > 0, 'Could not find any training data'\n",
    "\n",
    "#判断是否多通道，我觉得应该不是\n",
    "# no need to append an extra feature axis if data is multichannel\n",
    "add_feat_axis = not multichannel\n",
    "\n",
    "\n",
    "# if args.atlas:\n",
    "#     # scan-to-atlas generator\n",
    "#     atlas = vxm.py.utils.load_volfile(args.atlas, np_var='vol', add_batch_axis=True, add_feat_axis=add_feat_axis)\n",
    "#     generator = vxm.generators.scan_to_atlas(train_vol_names, atlas, batch_size=args.batch_size, bidir=args.bidir, add_feat_axis=add_feat_axis)\n",
    "# else:\n",
    "#     # scan-to-scan generator\n",
    "#     generator = vxm.generators.scan_to_scan(train_vol_names, batch_size=args.batch_size, bidir=args.bidir, add_feat_axis=add_feat_axis)\n",
    "\n",
    "\n",
    "# scan-to-atlas generator\n",
    "# 加载地图\n",
    "atlas = load_volfile(atlasdir, np_var='vol', add_batch_axis=True, add_feat_axis=add_feat_axis)\n",
    "# 输入数据生成器\n",
    "generator = scan_to_atlas(train_vol_names, atlas, batch_size=batch_size, bidir=bidir, add_feat_axis=add_feat_axis)\n",
    "\n",
    "# 生成的输入数据的大小\n",
    "# extract shape from sampled input\n",
    "inshape = next(generator)[0][0].shape[1:-1]\n",
    "\n",
    "# 创建模型存放的路径文件夹\n",
    "# prepare model folder\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# # device handling\n",
    "# gpus = args.gpu.split(',')\n",
    "# nb_gpus = len(gpus)\n",
    "# device = 'cuda'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "# assert args.batch_size >= nb_gpus, 'Batch size (%d) should be no less than the number of gpus (%d)' % (args.batch_size, nb_gpus)\n",
    "# device handling\n",
    "\n",
    "# 用gpu运行\n",
    "device = 'cuda'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "\n",
    "#是否禁用cudnn\n",
    "# enabling cudnn determinism appears to speed up training by a lot\n",
    "torch.backends.cudnn.deterministic = not cudnn_nondet\n",
    "\n",
    "# 设置Unet的结构参数，如果没设置，使用默认值\n",
    "# unet architecture\n",
    "enc_nf = enc if enc else [16, 32, 32, 32]\n",
    "dec_nf = dec if dec else [32, 32, 32, 32, 32, 16, 16]\n",
    "\n",
    "# 选择加载模型还是创建模型,此处先全部重新训练，不加载\n",
    "# if load_model:\n",
    "#     # load initial model (if specified)\n",
    "#     model = VxmDense.load(args.load_model, device)\n",
    "# else:\n",
    "#     # otherwise configure new model\n",
    "#     model = VxmDense(\n",
    "#         inshape=inshape,\n",
    "#         nb_unet_features=[enc_nf, dec_nf],\n",
    "#         bidir=bidir,\n",
    "#         int_steps=int_steps,\n",
    "#         int_downsize=int_downsize\n",
    "#     )\n",
    "model = VxmDense(\n",
    "    inshape=inshape,\n",
    "    nb_unet_features=[enc_nf, dec_nf],\n",
    "    bidir=bidir,\n",
    "    int_steps=int_steps,\n",
    "    int_downsize=int_downsize\n",
    ")\n",
    "\n",
    "# 如果多GPU，配置一下，我这里就不运行了，因为我只有一个GPU\n",
    "# if nb_gpus > 1:\n",
    "#     # use multiple GPUs via DataParallel\n",
    "#     model = torch.nn.DataParallel(model)\n",
    "#     model.save = model.module.save\n",
    "\n",
    "# 模型初始化\n",
    "# prepare the model for training and send to device\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# 设置优化器\n",
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# 设置损失函数\n",
    "# prepare image loss\n",
    "if image_loss == 'ncc':\n",
    "    image_loss_func = NCC().loss\n",
    "elif image_loss == 'mse':\n",
    "    image_loss_func = MSE().loss\n",
    "else:\n",
    "    raise ValueError('Image loss should be \"mse\" or \"ncc\", but found \"%s\"' % args.image_loss)\n",
    "\n",
    "# 设置是否使用双向损失函数\n",
    "# need two image loss functions if bidirectional\n",
    "if bidir:\n",
    "    losses  = [image_loss_func, image_loss_func]\n",
    "    weights = [0.5, 0.5]\n",
    "else:\n",
    "    losses  = [image_loss_func]\n",
    "    weights = [1]\n",
    "\n",
    "###############此处先使用默认的，后续改成题目要求的雅可比\n",
    "# 设置平滑loss\n",
    "# prepare deformation loss\n",
    "losses  += [Grad('l2', loss_mult=int_downsize).loss]\n",
    "weights += [lambda_weight]\n",
    "\n",
    "# 开始训练的循环\n",
    "# training loops\n",
    "for epoch in range(initial_epoch, epochs): #从0-5\n",
    "\n",
    "    # 保存当前epoch的模型参数\n",
    "    # save model checkpoint\n",
    "    model.save(os.path.join(model_dir, '%04d.pt' % epoch))\n",
    "\n",
    "    for step in range(steps_per_epoch):\n",
    "\n",
    "        # 可以改成tqdm实现\n",
    "        step_start_time = time.time()\n",
    "\n",
    "        # 加载两种输入数据\n",
    "        # generate inputs (and true outputs) and convert them to tensors\n",
    "        inputs, y_true = next(generator)\n",
    "        inputs = [torch.from_numpy(d).to(device).float().permute(0, 4, 1, 2, 3) for d in inputs]\n",
    "        y_true = [torch.from_numpy(d).to(device).float().permute(0, 4, 1, 2, 3) for d in y_true]\n",
    "\n",
    "        # 正向传播得到预测图像，现在不清楚迁移矢量图在哪里\n",
    "        # run inputs through the model to produce a warped image and flow field\n",
    "        y_pred = model(*inputs)\n",
    "\n",
    "        # 计算损失\n",
    "        # calculate total loss\n",
    "        loss = 0\n",
    "        loss_list = []\n",
    "        for n, loss_function in enumerate(losses):\n",
    "            curr_loss = loss_function(y_true[n], y_pred[n]) * weights[n] #两种loss方法进行计算，并按比例重新组合成100%\n",
    "            loss_list.append('%.6f' % curr_loss.item()) #保存当前loss作为统计信息\n",
    "            loss += curr_loss #计算总loss\n",
    "\n",
    "        loss_info = 'loss: %.6f  (%s)' % (loss.item(), ', '.join(loss_list)) #输出一下loss信息\n",
    "\n",
    "        # 反向传播进行参数优化\n",
    "        # backpropagate and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 在网络训练的时候输出信息\n",
    "        # print step info\n",
    "        epoch_info = 'epoch: %04d' % (epoch + 1)\n",
    "        step_info = ('step: %d/%d' % (step + 1, args.steps_per_epoch)).ljust(14)\n",
    "        time_info = 'time: %.2f sec' % (time.time() - step_start_time)\n",
    "        print('  '.join((epoch_info, step_info, time_info, loss_info)), flush=True)\n",
    "\n",
    "# final model save\n",
    "model.save(os.path.join(model_dir, '%04d.pt' % args.epochs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#register\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Example script to register two volumes with VoxelMorph models.\n",
    "\n",
    "Please make sure to use trained models appropriately. Let's say we have a model trained to register a\n",
    "scan (moving) to an atlas (fixed). To register a scan to the atlas and save the warp field, run:\n",
    "\n",
    "    register.py --moving moving.nii.gz --fixed fixed.nii.gz --model model.pt --moved moved.nii.gz --warp warp.nii.gz\n",
    "\n",
    "The source and target input images are expected to be affinely registered.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# import voxelmorph with pytorch backend\n",
    "os.environ['VXM_BACKEND'] = 'pytorch'\n",
    "\n",
    "\n",
    "\n",
    "# parse commandline args\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--moving', required=True, help='moving image (source) filename')\n",
    "parser.add_argument('--fixed', required=True, help='fixed image (target) filename')\n",
    "parser.add_argument('--moved', required=True, help='warped image output filename')\n",
    "parser.add_argument('--model', required=True, help='pytorch model for nonlinear registration')\n",
    "parser.add_argument('--warp', help='output warp deformation filename')\n",
    "parser.add_argument('-g', '--gpu', help='GPU number(s) - if not supplied, CPU is used')\n",
    "parser.add_argument('--multichannel', action='store_true', help='specify that data has multiple channels')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# device handling\n",
    "if args.gpu and (args.gpu != '-1'):\n",
    "    device = 'cuda'\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# load moving and fixed images\n",
    "add_feat_axis = not args.multichannel\n",
    "moving = vxm.py.utils.load_volfile(args.moving, add_batch_axis=True, add_feat_axis=add_feat_axis)\n",
    "fixed, fixed_affine = vxm.py.utils.load_volfile(args.fixed, add_batch_axis=True, add_feat_axis=add_feat_axis, ret_affine=True)\n",
    "\n",
    "# load and set up model\n",
    "model = vxm.networks.VxmDense.load(args.model, device)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# set up tensors and permute\n",
    "input_moving = torch.from_numpy(moving).to(device).float().permute(0, 4, 1, 2, 3)\n",
    "input_fixed = torch.from_numpy(fixed).to(device).float().permute(0, 4, 1, 2, 3)\n",
    "\n",
    "# predict\n",
    "moved, warp = model(input_moving, input_fixed, registration=True)\n",
    "\n",
    "# save moved image\n",
    "if args.moved:\n",
    "    moved = moved.detach().cpu().numpy().squeeze()\n",
    "    vxm.py.utils.save_volfile(moved, args.moved, fixed_affine)\n",
    "\n",
    "# save warp\n",
    "if args.warp:\n",
    "    warp = warp.detach().cpu().numpy().squeeze()\n",
    "    vxm.py.utils.save_volfile(warp, args.warp, fixed_affine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据可视化\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "# from matplotlib import pylab as plt\n",
    "# import nibabel as nib\n",
    "# from nibabel import nifti1\n",
    "# from nibabel.viewers import OrthoSlicer3D\n",
    " \n",
    "# example_filename = './data/fixed.nii.gz'\n",
    "# img = nib.load(example_filename)\n",
    "# print(img)\n",
    "# print(img.header['db_name'])  # 输出头信息\n",
    " \n",
    "# #shape有四个参数 patient001_4d.nii.gz\n",
    "# #shape有三个参数 patient001_frame01.nii.gz   patient001_frame12.nii.gz\n",
    "# #shape有三个参数  patient001_frame01_gt.nii.gz   patient001_frame12_gt.nii.gz\n",
    "# width, height, queue = img.dataobj.shape\n",
    "# OrthoSlicer3D(img.dataobj).show()\n",
    " \n",
    "# num = 1\n",
    "# for i in range(0, queue, 10):\n",
    "#     img_arr = img.dataobj[:, :, i]\n",
    "#     plt.subplot(5, 4, num)\n",
    "#     plt.imshow(img_arr, cmap='gray')\n",
    "#     num += 1\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vol', 'seg', 'train_avg']\n",
      "(160, 192, 224)\n",
      "(160, 192, 224)\n",
      "(256,)\n",
      "['vol']\n",
      "(160, 192, 224)\n",
      "['labels']\n",
      "['vol']\n",
      "['mapping']\n",
      "['init_mu', 'init_sigma']\n",
      "['vol', 'seg']\n"
     ]
    }
   ],
   "source": [
    "a=np.load('./data/atlas.npz')\n",
    "print(a.files)\n",
    "print(a['vol'].shape)\n",
    "print(a['seg'].shape)\n",
    "print(a['train_avg'].shape)\n",
    "b=np.load('./data/generated_uncond_atlas.npz')\n",
    "print(b.files)\n",
    "print(b['vol'].shape)\n",
    "c=np.load('./data/labels.npz')\n",
    "print(c.files)\n",
    "d=np.load('./data/prob_atlas.npz')\n",
    "print(d.files)\n",
    "e=np.load('./data/prob_atlas_mapping.npz')\n",
    "print(e.files)\n",
    "f=np.load('./data/prob_atlas_T1_stats.npz')\n",
    "print(f.files)\n",
    "g=np.load('./data/test_scan.npz')\n",
    "print(g.files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
