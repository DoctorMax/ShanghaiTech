{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def read_image_and_name(path):\n",
    "    imgdir = os.listdir(path)\n",
    "    imglst = []\n",
    "    imgs = []\n",
    "    for v in imgdir:\n",
    "        imglst.append(path + v)\n",
    "        imgs.append(cv2.imread(path + v))\n",
    "    print(imglst)\n",
    "    print('original images shape: ' + str(np.array(imgs).shape))\n",
    "    return imglst,imgs\n",
    "\n",
    "def read_label_and_name(path):\n",
    "    labeldir = os.listdir(path)\n",
    "    labellst = []\n",
    "    labels = []\n",
    "    for v in labeldir:\n",
    "        labellst.append(path + v)\n",
    "        labels.append(np.asarray(Image.open(path + v)))\n",
    "    print(labellst)\n",
    "    print('original labels shape: ' + str(np.array(labels).shape))\n",
    "    return labellst,labels\n",
    "\n",
    "def resize(imgs,resize_height, resize_width):\n",
    "    img_resize = []\n",
    "    for file in imgs:\n",
    "        img_resize.append(cv2.resize(file,(resize_height,resize_width)))\n",
    "    return img_resize\n",
    "\n",
    "#将N张576x576的图片裁剪成48x48\n",
    "#将N张576x592的图片裁剪成N*144个48x48\n",
    "def crop(image,dx):\n",
    "    list = []\n",
    "    for i in range(image.shape[0]):\n",
    "        for x in range(image.shape[1] // dx):#整除\n",
    "            for y in range(image.shape[2] // dx):\n",
    "                list.append(image[ i,  y*dx : (y+1)*dx,  x*dx : (x+1)*dx]) #这里的list一共append了20x12x12=2880次所以返回的shape是(2880,48,48)\n",
    "    return np.array(list)\n",
    "\n",
    "# 网络预测输出转换成图像子块\n",
    "# 网络预测输出 size=[Npatches, patch_height*patch_width, 2]\n",
    "def pred_to_imgs(pred, patch_height, patch_width, mode=\"original\"):\n",
    "    assert (len(pred.shape)==3)  #3D array: (Npatches,height*width,2)\n",
    "    assert (pred.shape[2]==2 )  #check the classes are 2  # 确认是否为二分类\n",
    "    pred_images = np.empty((pred.shape[0],pred.shape[1]))  #(Npatches,height*width)\n",
    "    if mode==\"original\": # 网络概率输出\n",
    "        for i in range(pred.shape[0]):\n",
    "            for pix in range(pred.shape[1]):\n",
    "                pred_images[i,pix]=pred[i,pix,1] #pred[:, :, 0] 是反分割图像输出 pred[:, :, 1]是分割输出\n",
    "    elif mode==\"threshold\": # 网络概率-阈值输出\n",
    "        for i in range(pred.shape[0]):\n",
    "            for pix in range(pred.shape[1]):\n",
    "                if pred[i,pix,1]>=0.5:\n",
    "                    pred_images[i,pix]=1\n",
    "                else:\n",
    "                    pred_images[i,pix]=0\n",
    "    else:\n",
    "        print(\"mode \" +str(mode) +\" not recognized, it can be 'original' or 'threshold'\")\n",
    "        exit()\n",
    "    # 输出形式改写成(Npatches,1, patch_height, patch_width)\n",
    "    pred_images = np.reshape(pred_images,(pred_images.shape[0],1, patch_height, patch_width))\n",
    "    return pred_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout #core内部定义了一系列常用的网络层，包括全连接、激活层等\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "def get_unet(n_ch,patch_height,patch_width):\n",
    "    inputs = Input(shape=(n_ch,patch_height,patch_width))\n",
    "    #data_format：字符串，“channels_first”或“channels_last”之一，代表图像的通道维的位置。\n",
    "    #以128x128的RGB图像为例，“channels_first”应将数据组织为（3,128,128），而“channels_last”应将数据组织为（128,128,3）。该参数的默认值是~/.keras/keras.json中设置的值，若从未设置过，则为“channels_last”。\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(inputs)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    #\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    #\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv3)\n",
    "\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up1 = concatenate([conv2,up1],axis=1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(up1)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv4)\n",
    "    #\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up2 = concatenate([conv1,up2], axis=1)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(up2)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv5)\n",
    "    #\n",
    "    #1×1的卷积的作用\n",
    "\t#大概有两个方面的作用：1. 实现跨通道的交互和信息整合2. 进行卷积核通道数的降维和升维。\n",
    "    conv6 = Conv2D(2, (1, 1), activation='relu',padding='same',data_format='channels_first')(conv5)\n",
    "    conv6 = core.Reshape((2,patch_height*patch_width))(conv6) #此时output的shape是(batchsize,2,patch_height*patch_width)\n",
    "    conv6 = core.Permute((2,1))(conv6)    #此时output的shape是(Npatch,patch_height*patch_width,2)即输出维度是(Npatch,2304,2)\n",
    "    ############\n",
    "    conv7 = core.Activation('softmax')(conv6)\n",
    "    model = Model(inputs=inputs, outputs=conv7)\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.3, nesterov=False)\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    '''\n",
    "    模型Model的compile方法:\n",
    "\tcompile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics = None, target_tensors=None)\n",
    "\t本函数编译模型以供训练，参数有\n",
    "\toptimizer：         优化器，为预定义优化器名或优化器对.可以在调用model.compile()之前初始化一个优化器对象，然后传入该函数。\n",
    "\tloss：              损失函数，为预定义损失函数名或一个目标函数\n",
    "\tmetrics：           列表，包含评估模型在训练和测试时的性能的指标，典型用法是metrics=['accuracy']如果要在多输出模型中为不同的输出指定不同的指标，可像该参数传递一个字典，例如metrics={'ouput_a': 'accuracy'}\n",
    "\tsample_weight_mode：如果需要按时间步为样本赋权（2D权矩阵），将该值设为“temporal”。默认为“None”，代表按样本赋权（1D权）。如果模型有多个输出，可以向该参数传入指定sample_weight_mode的字典或列表。在下面fit函数的解释中有相关的参考内容。\n",
    "\tweighted_metrics:   metrics列表，在训练和测试过程中，这些metrics将由sample_weight或clss_weight计算并赋权\n",
    "\ttarget_tensors:     默认情况下，Keras将为模型的目标创建一个占位符，该占位符在训练过程中将被目标数据代替。如果你想使用自己的目标张量（相应的，Keras将不会在训练时期望为这些目标张量载入外部的numpy数据），你可以通过该参数手动指定。目标张量可以是一个单独的张量（对应于单输出模型），也可以是一个张量列表，或者一个name->tensor的张量字典。\n",
    "\tkwargs：            使用TensorFlow作为后端请忽略该参数，若使用Theano/CNTK作为后端，kwargs的值将会传递给 K.function。如果使用TensorFlow为后端，这里的值会被传给tf.Session.run\n",
    "\t在Keras中，compile主要完成损失函数和优化器的一些配置，是为训练服务的。\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/train/image/21_training.tif', 'data/train/image/22_training.tif', 'data/train/image/23_training.tif', 'data/train/image/24_training.tif', 'data/train/image/25_training.tif', 'data/train/image/26_training.tif', 'data/train/image/27_training.tif', 'data/train/image/28_training.tif', 'data/train/image/29_training.tif', 'data/train/image/30_training.tif', 'data/train/image/31_training.tif', 'data/train/image/32_training.tif', 'data/train/image/33_training.tif', 'data/train/image/34_training.tif', 'data/train/image/35_training.tif', 'data/train/image/36_training.tif', 'data/train/image/37_training.tif', 'data/train/image/38_training.tif', 'data/train/image/39_training.tif', 'data/train/image/40_training.tif']\n",
      "original images shape: (20, 592, 576, 3)\n",
      "['data/train/mask/21_training.tif', 'data/train/mask/22_training.tif', 'data/train/mask/23_training.tif', 'data/train/mask/24_training.tif', 'data/train/mask/25_training.tif', 'data/train/mask/26_training.tif', 'data/train/mask/27_training.tif', 'data/train/mask/28_training.tif', 'data/train/mask/29_training.tif', 'data/train/mask/30_training.tif', 'data/train/mask/31_training.tif', 'data/train/mask/32_training.tif', 'data/train/mask/33_training.tif', 'data/train/mask/34_training.tif', 'data/train/mask/35_training.tif', 'data/train/mask/36_training.tif', 'data/train/mask/37_training.tif', 'data/train/mask/38_training.tif', 'data/train/mask/39_training.tif', 'data/train/mask/40_training.tif']\n",
      "original labels shape: (20, 592, 576, 3)\n",
      "(20, 592, 576, 3)\n",
      "(20, 592, 576, 3)\n",
      "Y_train shape: (2880, 48, 48)\n",
      "X_train shape: (2880, 3, 48, 48)\n",
      "Y_train shape: (2880, 2304)\n",
      "Y_train shape: (2880, 2304, 1)\n",
      "Y_train shape: (2880, 2304, 2)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 48, 48)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 48, 48)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 48, 48)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 48, 48)   9248        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 16, 24, 48)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 24, 48)   9280        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 24, 48)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 24, 48)   36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 12, 48)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 12, 48)  36992       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 12, 48)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 12, 48)  147584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 256, 24, 48)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 320, 24, 48)  0           conv2d_3[0][0]                   \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 24, 48)   184384      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 24, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 24, 48)   36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 48, 48)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 160, 48, 48)  0           conv2d_1[0][0]                   \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 48, 48)   46112       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 48, 48)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 48, 48)   9248        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 2, 48, 48)    66          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 2, 2304)      0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 2304, 2)      0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2304, 2)      0           permute[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 517,666\n",
      "Trainable params: 517,666\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.0559s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0140s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91661, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.3455 - accuracy: 0.9017 - val_loss: 0.2553 - val_accuracy: 0.9166\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.91661\n",
      "36/36 - 2s - loss: 0.2600 - accuracy: 0.9135 - val_loss: 0.2491 - val_accuracy: 0.9166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91661\n",
      "36/36 - 2s - loss: 0.2523 - accuracy: 0.9135 - val_loss: 0.2289 - val_accuracy: 0.9166\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.91661\n",
      "36/36 - 2s - loss: 0.2255 - accuracy: 0.9135 - val_loss: 0.1939 - val_accuracy: 0.9166\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91661 to 0.93972, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1993 - accuracy: 0.9254 - val_loss: 0.1783 - val_accuracy: 0.9397\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.93972 to 0.94318, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1892 - accuracy: 0.9350 - val_loss: 0.1734 - val_accuracy: 0.9432\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.94318 to 0.95440, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1672 - accuracy: 0.9445 - val_loss: 0.1441 - val_accuracy: 0.9544\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.95440 to 0.95589, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1603 - accuracy: 0.9476 - val_loss: 0.1379 - val_accuracy: 0.9559\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.95589 to 0.95719, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1524 - accuracy: 0.9513 - val_loss: 0.1373 - val_accuracy: 0.9572\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.95719 to 0.95773, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1472 - accuracy: 0.9537 - val_loss: 0.1353 - val_accuracy: 0.9577\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.95773 to 0.96034, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1441 - accuracy: 0.9552 - val_loss: 0.1282 - val_accuracy: 0.9603\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.96034 to 0.96065, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1432 - accuracy: 0.9556 - val_loss: 0.1254 - val_accuracy: 0.9606\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.96065\n",
      "36/36 - 2s - loss: 0.1405 - accuracy: 0.9567 - val_loss: 0.1270 - val_accuracy: 0.9582\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.96065 to 0.96198, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1391 - accuracy: 0.9574 - val_loss: 0.1225 - val_accuracy: 0.9620\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.96198\n",
      "36/36 - 2s - loss: 0.1374 - accuracy: 0.9577 - val_loss: 0.1245 - val_accuracy: 0.9607\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.96198 to 0.96264, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1191 - accuracy: 0.9580 - val_loss: 0.0984 - val_accuracy: 0.9626\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.96264 to 0.96286, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1113 - accuracy: 0.9595 - val_loss: 0.0979 - val_accuracy: 0.9629\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.96286\n",
      "36/36 - 2s - loss: 0.1102 - accuracy: 0.9598 - val_loss: 0.0975 - val_accuracy: 0.9623\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.96286 to 0.96377, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1095 - accuracy: 0.9601 - val_loss: 0.0959 - val_accuracy: 0.9638\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.96377\n",
      "36/36 - 2s - loss: 0.1078 - accuracy: 0.9605 - val_loss: 0.0966 - val_accuracy: 0.9628\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#参数和路径\n",
    "# resize_height, resize_width = (576, 576)\n",
    "resize_height, resize_width = (576, 592)\n",
    "dx = 48\n",
    "# img_path = 'DRIVE/training/images/'\n",
    "# label_path = 'DRIVE/training/1st_manual/'\n",
    "img_path = 'data/train/image/'\n",
    "label_path = 'data/train/mask/'\n",
    "\n",
    "\n",
    "#读取数据并resize\n",
    "imglst,images = read_image_and_name(img_path)\n",
    "labellst,labels = read_label_and_name(label_path)\n",
    "imgs_resize = resize(images,resize_height, resize_width)\n",
    "labels_resize = resize(labels,resize_height, resize_width)\n",
    "\n",
    "#将imgs列表和manuals列表转换成numpy数组\n",
    "X_train = np.array(imgs_resize)\n",
    "Y_train = np.array(labels_resize)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "#标准化\n",
    "X_train = X_train.astype('float32')/255\n",
    "Y_train = Y_train.astype('float32')/255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#将Y_train改为单通道？？\n",
    "Y_train=Y_train[...,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #提取训练集的G通道\n",
    "# X_train = X_train[...,1]\n",
    "\n",
    "# #对训练数据进行裁剪\n",
    "# X_train = crop(X_train,dx)\n",
    "# Y_train = crop(Y_train,dx)\n",
    "# print('X_train shape: '+str(X_train.shape)) #X_train(2880,48,48)\n",
    "# print('Y_train shape: '+str(Y_train.shape)) #Y_train(2880,48,48)\n",
    "\n",
    "# #X_train增加一维变成(2880,1,48,48)\n",
    "# X_train = X_train[:,np.newaxis, ...]\n",
    "# print('X_train shape: '+str(X_train.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#将单通道转换为三通道\n",
    "X_train_0=X_train[...,0]\n",
    "X_train_1=X_train[...,1]\n",
    "X_train_2=X_train[...,2]\n",
    "X_train_0 = crop(X_train_0,dx)\n",
    "X_train_1 = crop(X_train_1,dx)\n",
    "X_train_2 = crop(X_train_2,dx)\n",
    "Y_train = crop(Y_train,dx)\n",
    "X_train_0 = X_train_0[:,np.newaxis, ...]\n",
    "X_train_1 = X_train_1[:,np.newaxis, ...]\n",
    "X_train_2 = X_train_2[:,np.newaxis, ...]\n",
    "print('Y_train shape: '+str(Y_train.shape)) #Y_train(2880,48,48,3)\n",
    "X_train=np.concatenate((X_train_0,X_train_1,X_train_2),axis=1)\n",
    "print('X_train shape: '+str(X_train.shape)) #X_train(2880,3,48,48)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Y_train改变shape变成(2880,2304),保持第一维不变，其他维合并\n",
    "Y_train = Y_train.reshape(Y_train.shape[0],-1)\n",
    "print('Y_train shape: '+str(Y_train.shape))\n",
    "Y_train =Y_train[..., np.newaxis]  #增加一维变成(2880,2304,1)\n",
    "print('Y_train shape: '+str(Y_train.shape))\n",
    "temp = 1 - Y_train\n",
    "Y_train = np.concatenate([Y_train, temp], axis=2) #变成(2880,2304,2)\n",
    "print('Y_train shape: '+str(Y_train.shape))\n",
    "\n",
    "#获得model\n",
    "model = get_unet(X_train.shape[1],X_train.shape[2],X_train.shape[3])\n",
    "model.summary() #输出参数Param计算过程\n",
    "checkpointer = ModelCheckpoint(filepath='best_weights.h5',verbose=1,monitor='val_accuracy',mode='auto',save_best_only=True)\n",
    "model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,batch_size=64,epochs=20,verbose=2,shuffle=True,validation_split=0.2,callbacks=[checkpointer])\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test original shape: (592, 576, 3)\n",
      "Y_test original shape: (584, 565)\n",
      "input shape: (144, 3, 48, 48)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (3, 3, 1, 32) and (32, 3, 3, 3) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-86e3111524af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_unet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2209\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[0;32m   2210\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2211\u001b[1;33m         \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2213\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    706\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[0;32m    707\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m   \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3574\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3575\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3576\u001b[1;33m       \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3577\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3578\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[0mvalue_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m    860\u001b[0m           self.handle, value_tensor, name=name)\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \"\"\"\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (3, 3, 1, 32) and (32, 3, 3, 3) are incompatible"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# resize_height, resize_width = (576, 576)\n",
    "resize_height, resize_width = (576, 592)\n",
    "\n",
    "dx = 48\n",
    "#读取预测图片\n",
    "# imgs = cv2.imread('data/test/images/01_test.tif')[...,1] #读取G通道\n",
    "imgs = cv2.imread('data/test/images/01_test.tif') #读取G通道\n",
    "imgs = np.array(cv2.resize(imgs,(resize_height,resize_width))) #imgs现在是576x576大小\n",
    "#读取预测图片的标签\n",
    "label = np.array(Image.open('data/test/mask/01_test.tif'))\n",
    "#预测图片和标签标准化\n",
    "X_test = imgs.astype('float32')/255\n",
    "print('X_test original shape: '+str(X_test.shape))\n",
    "Y_test = label.astype('float32')/255\n",
    "print('Y_test original shape: '+str(Y_test.shape))\n",
    "\n",
    "\n",
    "#对预测图片进行裁剪按行优先，裁剪成(144,48,48)\n",
    "X_test_0=X_test[...,0]\n",
    "X_test_1=X_test[...,1]\n",
    "X_test_2=X_test[...,2]\n",
    "np.resize(X_test_0,(resize_height, resize_width))\n",
    "np.resize(X_test_1,(resize_height, resize_width))\n",
    "np.resize(X_test_2,(resize_height, resize_width))\n",
    "\n",
    "\n",
    "\n",
    "list_0 = []\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        list_0.append(X_test_0[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "X_test_0 = np.array(list_0)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "list_1 = []\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        list_1.append(X_test_1[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "X_test_1 = np.array(list_1)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "list_2 = []\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        list_2.append(X_test_2[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "X_test_2 = np.array(list_2)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "\n",
    "\n",
    "#X_test换channel位置\n",
    "X_test=np.concatenate((X_test_0,X_test_1,X_test_2),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print('input shape: '+str(X_test.shape))\n",
    "\n",
    "#加载模型和权重并预测\n",
    "model = get_unet(1,dx,dx)\n",
    "\n",
    "model.load_weights('best_weights.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test=X_test[:,0,:,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print('predict shape: '+str(Y_pred.shape)) #预测结果的shape是(Npatches,patch_height*patch_width,2)\n",
    "\n",
    "#把预测输出的numpy数组拼接还原再显示\n",
    "Y_pred = Y_pred[..., 0]  #二分类提取出分割前景 现在Y_pred的shape是(144,2304) 且这个144是按照行优先来拼接的\n",
    "\n",
    "#对预测结果进行拼接，将(144,2304)拼接成(576,576)\n",
    "t=0\n",
    "image = np.zeros((resize_height,resize_width))\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        temp = Y_pred[t].reshape(dx,dx)\n",
    "        image[i*dx:(i+1)*dx, j*dx:(j+1)*dx] = temp\n",
    "        t = t+1\n",
    "image = cv2.resize(image,((Y_test.shape[1], Y_test.shape[0]))) #将576x576大小的图像还原成原图像大小\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(Y_test)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
