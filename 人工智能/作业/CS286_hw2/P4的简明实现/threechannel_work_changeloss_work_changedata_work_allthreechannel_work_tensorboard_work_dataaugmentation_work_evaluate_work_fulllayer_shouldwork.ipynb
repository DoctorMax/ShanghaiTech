{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def read_image_and_name(path):\n",
    "    imgdir = os.listdir(path)\n",
    "    imglst = []\n",
    "    imgs = []\n",
    "    for v in imgdir:\n",
    "        imglst.append(path + v)\n",
    "        imgs.append(cv2.imread(path + v))\n",
    "    print(imglst)\n",
    "    print('original images shape: ' + str(np.array(imgs).shape))\n",
    "    return imglst,imgs\n",
    "\n",
    "def read_label_and_name(path):\n",
    "    labeldir = os.listdir(path)\n",
    "    labellst = []\n",
    "    labels = []\n",
    "    for v in labeldir:\n",
    "        labellst.append(path + v)\n",
    "        labels.append(np.asarray(Image.open(path + v)))\n",
    "    print(labellst)\n",
    "    print('original labels shape: ' + str(np.array(labels).shape))\n",
    "    return labellst,labels\n",
    "\n",
    "def resize(imgs,resize_height, resize_width):\n",
    "    img_resize = []\n",
    "    for file in imgs:\n",
    "        img_resize.append(cv2.resize(file,(resize_height,resize_width)))\n",
    "    return img_resize\n",
    "\n",
    "\n",
    "def SaltAndPepper(src,percetage):  \n",
    "    list=[]\n",
    "    for j in range(src.shape[0]):\n",
    "        SP_NoiseImg=src[j].copy()\n",
    "        SP_NoiseNum=int(percetage*src[j].shape[0]*src[j].shape[1]) \n",
    "        for i in range(SP_NoiseNum): \n",
    "            randR=np.random.randint(0,src[j].shape[0]-1) \n",
    "            randG=np.random.randint(0,src[j].shape[1]-1) \n",
    "            randB=np.random.randint(0,3)\n",
    "            if np.random.randint(0,1)==0: \n",
    "                SP_NoiseImg[randR,randG,randB]=0 \n",
    "            else: \n",
    "                SP_NoiseImg[randR,randG,randB]=255 \n",
    "        list.append(src[j])\n",
    "        list.append(SP_NoiseImg)\n",
    "    return np.array(list)\n",
    "\n",
    "def rotate(image, angle=15, scale=0.9):\n",
    "    list=[]\n",
    "    for j in range(image.shape[0]):\n",
    "        w = image[j].shape[1]\n",
    "        h = image[j].shape[0]\n",
    "        #rotate matrix\n",
    "        M = cv2.getRotationMatrix2D((w/2,h/2), angle, scale)\n",
    "        #rotate\n",
    "        image2 = cv2.warpAffine(image[j],M,(w,h))\n",
    "        list.append(image[j])\n",
    "        list.append(image2)\n",
    "    return np.array(list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#将N张576x576的图片裁剪成48x48\n",
    "def crop(image,dx):\n",
    "    list = []\n",
    "    for i in range(image.shape[0]):\n",
    "        for x in range(image.shape[1] // dx):\n",
    "            for y in range(image.shape[2] // dx):\n",
    "                list.append(image[ i,  y*dx : (y+1)*dx,  x*dx : (x+1)*dx]) #这里的list一共append了20x12x12=2880次所以返回的shape是(2880,48,48)\n",
    "    return np.array(list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dice_coefficient(a,b):\n",
    "    return 2.*np.sum(a*b)/(np.sum(a)+np.sum(b))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 网络预测输出转换成图像子块\n",
    "# 网络预测输出 size=[Npatches, patch_height*patch_width, 2]\n",
    "def pred_to_imgs(pred, patch_height, patch_width, mode=\"original\"):\n",
    "    assert (len(pred.shape)==3)  #3D array: (Npatches,height*width,2)\n",
    "    assert (pred.shape[2]==2 )  #check the classes are 2  # 确认是否为二分类\n",
    "    pred_images = np.empty((pred.shape[0],pred.shape[1]))  #(Npatches,height*width)\n",
    "    if mode==\"original\": # 网络概率输出\n",
    "        for i in range(pred.shape[0]):\n",
    "            for pix in range(pred.shape[1]):\n",
    "                pred_images[i,pix]=pred[i,pix,1] #pred[:, :, 0] 是反分割图像输出 pred[:, :, 1]是分割输出\n",
    "    elif mode==\"threshold\": # 网络概率-阈值输出\n",
    "        for i in range(pred.shape[0]):\n",
    "            for pix in range(pred.shape[1]):\n",
    "                if pred[i,pix,1]>=0.5:\n",
    "                    pred_images[i,pix]=1\n",
    "                else:\n",
    "                    pred_images[i,pix]=0\n",
    "    else:\n",
    "        print(\"mode \" +str(mode) +\" not recognized, it can be 'original' or 'threshold'\")\n",
    "        exit()\n",
    "    # 输出形式改写成(Npatches,1, patch_height, patch_width)\n",
    "    pred_images = np.reshape(pred_images,(pred_images.shape[0],1, patch_height, patch_width))\n",
    "    return pred_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout #core内部定义了一系列常用的网络层，包括全连接、激活层等\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "def get_unet(n_ch,patch_height,patch_width):\n",
    "    inputs = Input(shape=(n_ch,patch_height,patch_width))\n",
    "    #data_format：字符串，“channels_first”或“channels_last”之一，代表图像的通道维的位置。\n",
    "    #以128x128的RGB图像为例，“channels_first”应将数据组织为（3,128,128），而“channels_last”应将数据组织为（128,128,3）。该参数的默认值是~/.keras/keras.json中设置的值，若从未设置过，则为“channels_last”。\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(inputs)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    #\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    #\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    #\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool3)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    #\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool4)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv5)\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    up1 = concatenate([conv4,up1],axis=1)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same',data_format='channels_first')(up1)\n",
    "    conv6 = Dropout(0.2)(conv6)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv6)\n",
    "    #\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    up2 = concatenate([conv3,up2], axis=1)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same',data_format='channels_first')(up2)\n",
    "    conv7 = Dropout(0.2)(conv7)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv7)\n",
    "    #\n",
    "    up3 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    up3 = concatenate([conv2,up3], axis=1)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(up3)\n",
    "    conv8 = Dropout(0.2)(conv8)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv8)\n",
    "    #\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    up4 = concatenate([conv1,up4], axis=1)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(up4)\n",
    "    conv9 = Dropout(0.2)(conv9)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv9)\n",
    "    #\n",
    "    #1×1的卷积的作用\n",
    "\t#大概有两个方面的作用：1. 实现跨通道的交互和信息整合2. 进行卷积核通道数的降维和升维。\n",
    "    conv10 = Conv2D(2, (1, 1), activation='relu',padding='same',data_format='channels_first')(conv9)\n",
    "    conv10 = core.Reshape((2,patch_height*patch_width))(conv10) #此时output的shape是(batchsize,2,patch_height*patch_width)\n",
    "    conv10 = core.Permute((2,1))(conv10)    #此时output的shape是(Npatch,patch_height*patch_width,2)即输出维度是(Npatch,2304,2)\n",
    "    ############\n",
    "    conv11 = core.Activation('softmax')(conv10)\n",
    "    model = Model(inputs=inputs, outputs=conv11)\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.3, nesterov=False)\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    '''\n",
    "    模型Model的compile方法:\n",
    "\tcompile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics = None, target_tensors=None)\n",
    "\t本函数编译模型以供训练，参数有\n",
    "\toptimizer：         优化器，为预定义优化器名或优化器对.可以在调用model.compile()之前初始化一个优化器对象，然后传入该函数。\n",
    "\tloss：              损失函数，为预定义损失函数名或一个目标函数\n",
    "\tmetrics：           列表，包含评估模型在训练和测试时的性能的指标，典型用法是metrics=['accuracy']如果要在多输出模型中为不同的输出指定不同的指标，可像该参数传递一个字典，例如metrics={'ouput_a': 'accuracy'}\n",
    "\tsample_weight_mode：如果需要按时间步为样本赋权（2D权矩阵），将该值设为“temporal”。默认为“None”，代表按样本赋权（1D权）。如果模型有多个输出，可以向该参数传入指定sample_weight_mode的字典或列表。在下面fit函数的解释中有相关的参考内容。\n",
    "\tweighted_metrics:   metrics列表，在训练和测试过程中，这些metrics将由sample_weight或clss_weight计算并赋权\n",
    "\ttarget_tensors:     默认情况下，Keras将为模型的目标创建一个占位符，该占位符在训练过程中将被目标数据代替。如果你想使用自己的目标张量（相应的，Keras将不会在训练时期望为这些目标张量载入外部的numpy数据），你可以通过该参数手动指定。目标张量可以是一个单独的张量（对应于单输出模型），也可以是一个张量列表，或者一个name->tensor的张量字典。\n",
    "\tkwargs：            使用TensorFlow作为后端请忽略该参数，若使用Theano/CNTK作为后端，kwargs的值将会传递给 K.function。如果使用TensorFlow为后端，这里的值会被传给tf.Session.run\n",
    "\t在Keras中，compile主要完成损失函数和优化器的一些配置，是为训练服务的。\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/train/image/21_training.tif', 'data/train/image/22_training.tif', 'data/train/image/23_training.tif', 'data/train/image/24_training.tif', 'data/train/image/25_training.tif', 'data/train/image/26_training.tif', 'data/train/image/27_training.tif', 'data/train/image/28_training.tif', 'data/train/image/29_training.tif', 'data/train/image/30_training.tif', 'data/train/image/31_training.tif', 'data/train/image/32_training.tif', 'data/train/image/33_training.tif', 'data/train/image/34_training.tif', 'data/train/image/35_training.tif', 'data/train/image/36_training.tif', 'data/train/image/37_training.tif', 'data/train/image/38_training.tif', 'data/train/image/39_training.tif', 'data/train/image/40_training.tif']\n",
      "original images shape: (20, 592, 576, 3)\n",
      "['data/train/mask/21_training.tif', 'data/train/mask/22_training.tif', 'data/train/mask/23_training.tif', 'data/train/mask/24_training.tif', 'data/train/mask/25_training.tif', 'data/train/mask/26_training.tif', 'data/train/mask/27_training.tif', 'data/train/mask/28_training.tif', 'data/train/mask/29_training.tif', 'data/train/mask/30_training.tif', 'data/train/mask/31_training.tif', 'data/train/mask/32_training.tif', 'data/train/mask/33_training.tif', 'data/train/mask/34_training.tif', 'data/train/mask/35_training.tif', 'data/train/mask/36_training.tif', 'data/train/mask/37_training.tif', 'data/train/mask/38_training.tif', 'data/train/mask/39_training.tif', 'data/train/mask/40_training.tif']\n",
      "original labels shape: (20, 592, 576, 3)\n",
      "X_train.shape(20, 576, 576, 3)\n",
      "Y_train.shape(20, 576, 576, 3)\n",
      "X_train.shape:(40, 576, 576, 3)\n",
      "Y_train.shape:(40, 576, 576, 3)\n",
      "X_train.shape:(80, 576, 576, 3)\n",
      "Y_train.shape:(80, 576, 576, 3)\n",
      "X_train_0.shape:(80, 576, 576)\n",
      "X_train_1.shape:(80, 576, 576)\n",
      "X_train_2.shape:(80, 576, 576)\n",
      "X_train_0.shape:(11520, 48, 48)\n",
      "X_train_1.shape:(11520, 48, 48)\n",
      "X_train_2.shape:(11520, 48, 48)\n",
      "Y_train.shape:(11520, 48, 48, 3)\n",
      "X_train_0.shape:(11520, 1, 48, 48)\n",
      "X_train_1.shape:(11520, 1, 48, 48)\n",
      "X_train_2.shape:(11520, 1, 48, 48)\n",
      "X_train.shape:(11520, 3, 48, 48)\n",
      "Y_train.shape:(11520, 48, 48)\n",
      "Y_train shape: (11520, 2304)\n",
      "Y_train shape: (11520, 2304, 1)\n",
      "Y_train shape: (11520, 2304, 2)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 48, 48)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 48, 48)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 48, 48)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 48, 48)   36928       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 24, 48)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 24, 48)  36992       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 24, 48)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 24, 48)  147584      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 12, 48)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 12, 48)  147712      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256, 12, 48)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 12, 48)  590080      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 128, 6, 48)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 512, 6, 48)   590336      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512, 6, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 512, 6, 48)   2359808     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 256, 3, 48)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1024, 3, 48)  2360320     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024, 3, 48)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1024, 3, 48)  9438208     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 2048, 6, 48)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2560, 6, 48)  0           conv2d_7[0][0]                   \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 512, 6, 48)   11796992    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512, 6, 48)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 512, 6, 48)   2359808     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 1024, 12, 48) 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1280, 12, 48) 0           conv2d_5[0][0]                   \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 12, 48)  2949376     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256, 12, 48)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 12, 48)  590080      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 512, 24, 48)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 640, 24, 48)  0           conv2d_3[0][0]                   \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 24, 48)  737408      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128, 24, 48)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 24, 48)  147584      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 48, 48)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 320, 48, 48)  0           conv2d_1[0][0]                   \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 48, 48)   184384      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 48, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 48, 48)   36928       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 2, 48, 48)    130         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 2, 2304)      0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 2304, 2)      0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2304, 2)      0           permute[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 34,512,450\n",
      "Trainable params: 34,512,450\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[16,320,48,48] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node functional_1/concatenate_3/concat (defined at <ipython-input-3-5ab77516a486>:152) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_2983]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5ab77516a486>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32ml:\\anaconda3\\envs\\cs286\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[16,320,48,48] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node functional_1/concatenate_3/concat (defined at <ipython-input-3-5ab77516a486>:152) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_2983]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.compat.v1 import GPUOptions\n",
    "\n",
    "gpu_options = GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "config = ConfigProto(gpu_options=gpu_options)\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#参数和路径\n",
    "resize_height, resize_width = (576, 576)\n",
    "dx = 48\n",
    "# img_path = 'DRIVE/training/images/'\n",
    "# label_path = 'DRIVE/training/1st_manual/'\n",
    "img_path = 'data/train/image/'\n",
    "label_path = 'data/train/mask/'\n",
    "\n",
    "\n",
    "#读取数据并resize\n",
    "imglst,images = read_image_and_name(img_path)\n",
    "labellst,labels = read_label_and_name(label_path)\n",
    "imgs_resize = resize(images,resize_height, resize_width)\n",
    "labels_resize = resize(labels,resize_height, resize_width)\n",
    "\n",
    "#将imgs列表和manuals列表转换成numpy数组\n",
    "X_train = np.array(imgs_resize)\n",
    "print('X_train.shape'+str(X_train.shape))\n",
    "Y_train = np.array(labels_resize)\n",
    "print('Y_train.shape'+str(Y_train.shape))\n",
    "\n",
    "#标准化\n",
    "X_train = X_train.astype('float32')/255\n",
    "Y_train = Y_train.astype('float32')/255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #提取训练集的G通道\n",
    "# X_train = X_train[...,1]\n",
    "\n",
    "# #对训练数据进行裁剪\n",
    "# X_train = crop(X_train,dx)\n",
    "# Y_train = crop(Y_train,dx)\n",
    "# print('X_train shape: '+str(X_train.shape)) #X_train(2880,48,48)\n",
    "# print('Y_train shape: '+str(Y_train.shape)) #Y_train(2880,48,48)\n",
    "\n",
    "# #X_train增加一维变成(2880,1,48,48)\n",
    "# X_train = X_train[:,np.newaxis, ...]\n",
    "# print('X_train shape: '+str(X_train.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############图像增强\n",
    "X_train=rotate(X_train,angle=10,scale=1)\n",
    "print('X_train.shape:'+str(X_train.shape))\n",
    "Y_train=rotate(Y_train,angle=10,scale=1)\n",
    "print('Y_train.shape:'+str(Y_train.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train=SaltAndPepper(X_train,0.1)\n",
    "print('X_train.shape:'+str(X_train.shape))\n",
    "Y_train=SaltAndPepper(Y_train,0)\n",
    "print('Y_train.shape:'+str(Y_train.shape))\n",
    "\n",
    "\n",
    "\n",
    "#将单通道转换为三通道\n",
    "X_train_0=X_train[...,0]\n",
    "print('X_train_0.shape:'+str(X_train_0.shape))\n",
    "X_train_1=X_train[...,1]\n",
    "print('X_train_1.shape:'+str(X_train_1.shape))\n",
    "X_train_2=X_train[...,2]\n",
    "print('X_train_2.shape:'+str(X_train_2.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_0 = crop(X_train_0,dx)\n",
    "print('X_train_0.shape:'+str(X_train_0.shape))\n",
    "X_train_1 = crop(X_train_1,dx)\n",
    "print('X_train_1.shape:'+str(X_train_1.shape))\n",
    "X_train_2 = crop(X_train_2,dx)\n",
    "print('X_train_2.shape:'+str(X_train_2.shape))\n",
    "Y_train = crop(Y_train,dx)\n",
    "print('Y_train.shape:'+str(Y_train.shape))#Y_train(2880,48,48)\n",
    "X_train_0 = X_train_0[:,np.newaxis, ...]\n",
    "print('X_train_0.shape:'+str(X_train_0.shape))\n",
    "X_train_1 = X_train_1[:,np.newaxis, ...]\n",
    "print('X_train_1.shape:'+str(X_train_1.shape))\n",
    "X_train_2 = X_train_2[:,np.newaxis, ...]\n",
    "print('X_train_2.shape:'+str(X_train_2.shape))\n",
    "\n",
    "X_train=np.concatenate((X_train_0,X_train_1,X_train_2),axis=1)\n",
    "print('X_train.shape:'+str(X_train.shape))\n",
    "\n",
    "\n",
    "\n",
    "#将Y_train改为单通道？？\n",
    "Y_train=Y_train[...,0]\n",
    "print('Y_train.shape:'+str(Y_train.shape))\n",
    "\n",
    "\n",
    "\n",
    "#Y_train改变shape变成(2880,2304),保持第一维不变，其他维合并\n",
    "Y_train = Y_train.reshape(Y_train.shape[0],-1)\n",
    "print('Y_train shape: '+str(Y_train.shape))\n",
    "Y_train =Y_train[..., np.newaxis]  #增加一维变成(2880,2304,1)\n",
    "print('Y_train shape: '+str(Y_train.shape))\n",
    "temp = 1 - Y_train\n",
    "Y_train = np.concatenate([Y_train, temp], axis=2) #变成(2880,2304,2)\n",
    "print('Y_train shape: '+str(Y_train.shape))\n",
    "\n",
    "#获得model\n",
    "model = get_unet(X_train.shape[1],X_train.shape[2],X_train.shape[3])\n",
    "model.summary() #输出参数Param计算过程\n",
    "checkpointer = ModelCheckpoint(filepath='best_weights.h5',verbose=1,monitor='val_accuracy',mode='auto',save_best_only=True)\n",
    "model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train,Y_train,batch_size=16,epochs=20,verbose=2,shuffle=True,validation_split=0.2,callbacks=[checkpointer,tensorboard_callback])\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "resize_height, resize_width = (576, 576)\n",
    "dx = 48\n",
    "#读取预测图片\n",
    "# imgs = cv2.imread('data/test/images/01_test.tif')[...,1] #读取G通道\n",
    "imgs = cv2.imread('data/test/images/01_test.tif') #读取G通道\n",
    "imgs = np.array(cv2.resize(imgs,(resize_height,resize_width))) #imgs现在是576x576大小\n",
    "#读取预测图片的标签\n",
    "label = np.array(Image.open('data/test/mask/01_test.tif'))\n",
    "print(label.shape)\n",
    "\n",
    "\n",
    "label = np.array(cv2.resize(label,(resize_height, resize_width)))\n",
    "print(label.shape)\n",
    "\n",
    "\n",
    "\n",
    "#预测图片和标签标准化\n",
    "X_test = imgs.astype('float32')/255\n",
    "print('X_test original shape: '+str(X_test.shape))\n",
    "Y_test = label.astype('float32')/255\n",
    "\n",
    "\n",
    "#对预测图片进行裁剪按行优先，裁剪成(144,48,48)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# list = []\n",
    "# for i in range(resize_height//dx):\n",
    "#     for j in range(resize_width//dx):\n",
    "#         list.append(X_test[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "# X_test = np.array(list)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test_0=X_test[...,0]\n",
    "X_test_1=X_test[...,1]\n",
    "X_test_2=X_test[...,2]\n",
    "list_0 = []\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        list_0.append(X_test_0[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "X_test_0 = np.array(list_0)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "list_1 = []\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        list_1.append(X_test_1[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "X_test_1 = np.array(list_1)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "list_2 = []\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        list_2.append(X_test_2[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "X_test_2 = np.array(list_2)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "\n",
    "\n",
    "#X_test换channel位置\n",
    "X_test=np.concatenate((X_test_0,X_test_1,X_test_2),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('input shape: '+str(X_test.shape))\n",
    "\n",
    "#加载模型和权重并预测\n",
    "model = get_unet(X_test.shape[1],X_test.shape[2],X_test.shape[3])\n",
    "\n",
    "\n",
    "model.load_weights('best_weights.h5')\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print('predict shape: '+str(Y_pred.shape)) #预测结果的shape是(Npatches,patch_height*patch_width,2)\n",
    "\n",
    "#把预测输出的numpy数组拼接还原再显示\n",
    "Y_pred = Y_pred[..., 0]  #二分类提取出分割前景 现在Y_pred的shape是(144,2304) 且这个144是按照行优先来拼接的\n",
    "\n",
    "#对预测结果进行拼接，将(144,2304)拼接成(576,576)\n",
    "t=0\n",
    "image = np.zeros((resize_height,resize_width))\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        temp = Y_pred[t].reshape(dx,dx)\n",
    "        image[i*dx:(i+1)*dx, j*dx:(j+1)*dx] = temp\n",
    "        t = t+1\n",
    "image = cv2.resize(image,((Y_test.shape[1], Y_test.shape[0]))) #将576x576大小的图像还原成原图像大小\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(Y_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice =dice_coefficient(image,Y_test)\n",
    "iou=dice/(2-dice)\n",
    "print(dice)\n",
    "print(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import morphology\n",
    "\n",
    "def surfd(input1, input2, sampling=1, connectivity=1):\n",
    "\n",
    "    input_1 = np.atleast_1d(input1.astype(np.bool))\n",
    "    input_2 = np.atleast_1d(input2.astype(np.bool))\n",
    "    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)\n",
    "    S = (input_1.astype('uint8') - (morphology.binary_erosion(input_1, conn).astype('uint8'))).astype('bool')\n",
    "    Sprime = (input_2.astype('uint8') - (morphology.binary_erosion(input_2, conn))).astype('uint8')\n",
    "\n",
    "    # S = input_1 - morphology.binary_erosion(input_1, conn)\n",
    "    # Sprime = input_2 - morphology.binary_erosion(input_2, conn)\n",
    "\n",
    "    dta = morphology.distance_transform_edt(~S,sampling)\n",
    "    dtb = morphology.distance_transform_edt(~Sprime,sampling)\n",
    "\n",
    "    sds = np.concatenate([np.ravel(dta[Sprime!=0]), np.ravel(dtb[S!=0])])\n",
    "    return sds\n",
    "\n",
    "assd=np.mean(surfd(image,Y_test,sampling=1, connectivity=1))\n",
    "assd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=np.array([[1,2],[3,4]])\n",
    "# b=np.array([[1,2],[3,4]])\n",
    "# np.dot(a,b)#矩阵乘法\n",
    "# a*b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
