{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def read_image_and_name(path):\n",
    "    imgdir = os.listdir(path)\n",
    "    imglst = []\n",
    "    imgs = []\n",
    "    for v in imgdir:\n",
    "        imglst.append(path + v)\n",
    "        imgs.append(cv2.imread(path + v))\n",
    "    print(imglst)\n",
    "    print('original images shape: ' + str(np.array(imgs).shape))\n",
    "    return imglst,imgs\n",
    "\n",
    "def read_label_and_name(path):\n",
    "    labeldir = os.listdir(path)\n",
    "    labellst = []\n",
    "    labels = []\n",
    "    for v in labeldir:\n",
    "        labellst.append(path + v)\n",
    "        labels.append(np.asarray(Image.open(path + v)))\n",
    "    print(labellst)\n",
    "    print('original labels shape: ' + str(np.array(labels).shape))\n",
    "    return labellst,labels\n",
    "\n",
    "def resize(imgs,resize_height, resize_width):\n",
    "    img_resize = []\n",
    "    for file in imgs:\n",
    "        img_resize.append(cv2.resize(file,(resize_height,resize_width)))\n",
    "    return img_resize\n",
    "\n",
    "#将N张576x576的图片裁剪成48x48\n",
    "def crop(image,dx):\n",
    "    list = []\n",
    "    for i in range(image.shape[0]):\n",
    "        for x in range(image.shape[1] // dx):\n",
    "            for y in range(image.shape[2] // dx):\n",
    "                list.append(image[ i,  y*dx : (y+1)*dx,  x*dx : (x+1)*dx]) #这里的list一共append了20x12x12=2880次所以返回的shape是(2880,48,48)\n",
    "    return np.array(list)\n",
    "\n",
    "# 网络预测输出转换成图像子块\n",
    "# 网络预测输出 size=[Npatches, patch_height*patch_width, 2]\n",
    "def pred_to_imgs(pred, patch_height, patch_width, mode=\"original\"):\n",
    "    assert (len(pred.shape)==3)  #3D array: (Npatches,height*width,2)\n",
    "    assert (pred.shape[2]==2 )  #check the classes are 2  # 确认是否为二分类\n",
    "    pred_images = np.empty((pred.shape[0],pred.shape[1]))  #(Npatches,height*width)\n",
    "    if mode==\"original\": # 网络概率输出\n",
    "        for i in range(pred.shape[0]):\n",
    "            for pix in range(pred.shape[1]):\n",
    "                pred_images[i,pix]=pred[i,pix,1] #pred[:, :, 0] 是反分割图像输出 pred[:, :, 1]是分割输出\n",
    "    elif mode==\"threshold\": # 网络概率-阈值输出\n",
    "        for i in range(pred.shape[0]):\n",
    "            for pix in range(pred.shape[1]):\n",
    "                if pred[i,pix,1]>=0.5:\n",
    "                    pred_images[i,pix]=1\n",
    "                else:\n",
    "                    pred_images[i,pix]=0\n",
    "    else:\n",
    "        print(\"mode \" +str(mode) +\" not recognized, it can be 'original' or 'threshold'\")\n",
    "        exit()\n",
    "    # 输出形式改写成(Npatches,1, patch_height, patch_width)\n",
    "    pred_images = np.reshape(pred_images,(pred_images.shape[0],1, patch_height, patch_width))\n",
    "    return pred_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout #core内部定义了一系列常用的网络层，包括全连接、激活层等\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "def get_unet(n_ch,patch_height,patch_width):\n",
    "    inputs = Input(shape=(n_ch,patch_height,patch_width))\n",
    "    #data_format：字符串，“channels_first”或“channels_last”之一，代表图像的通道维的位置。\n",
    "    #以128x128的RGB图像为例，“channels_first”应将数据组织为（3,128,128），而“channels_last”应将数据组织为（128,128,3）。该参数的默认值是~/.keras/keras.json中设置的值，若从未设置过，则为“channels_last”。\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(inputs)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    #\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    #\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv3)\n",
    "\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up1 = concatenate([conv2,up1],axis=1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(up1)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv4)\n",
    "    #\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up2 = concatenate([conv1,up2], axis=1)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(up2)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv5)\n",
    "    #\n",
    "    #1×1的卷积的作用\n",
    "\t#大概有两个方面的作用：1. 实现跨通道的交互和信息整合2. 进行卷积核通道数的降维和升维。\n",
    "    conv6 = Conv2D(2, (1, 1), activation='relu',padding='same',data_format='channels_first')(conv5)\n",
    "    conv6 = core.Reshape((2,patch_height*patch_width))(conv6) #此时output的shape是(batchsize,2,patch_height*patch_width)\n",
    "    conv6 = core.Permute((2,1))(conv6)    #此时output的shape是(Npatch,patch_height*patch_width,2)即输出维度是(Npatch,2304,2)\n",
    "    ############\n",
    "    conv7 = core.Activation('softmax')(conv6)\n",
    "    model = Model(inputs=inputs, outputs=conv7)\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.3, nesterov=False)\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    '''\n",
    "    模型Model的compile方法:\n",
    "\tcompile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics = None, target_tensors=None)\n",
    "\t本函数编译模型以供训练，参数有\n",
    "\toptimizer：         优化器，为预定义优化器名或优化器对.可以在调用model.compile()之前初始化一个优化器对象，然后传入该函数。\n",
    "\tloss：              损失函数，为预定义损失函数名或一个目标函数\n",
    "\tmetrics：           列表，包含评估模型在训练和测试时的性能的指标，典型用法是metrics=['accuracy']如果要在多输出模型中为不同的输出指定不同的指标，可像该参数传递一个字典，例如metrics={'ouput_a': 'accuracy'}\n",
    "\tsample_weight_mode：如果需要按时间步为样本赋权（2D权矩阵），将该值设为“temporal”。默认为“None”，代表按样本赋权（1D权）。如果模型有多个输出，可以向该参数传入指定sample_weight_mode的字典或列表。在下面fit函数的解释中有相关的参考内容。\n",
    "\tweighted_metrics:   metrics列表，在训练和测试过程中，这些metrics将由sample_weight或clss_weight计算并赋权\n",
    "\ttarget_tensors:     默认情况下，Keras将为模型的目标创建一个占位符，该占位符在训练过程中将被目标数据代替。如果你想使用自己的目标张量（相应的，Keras将不会在训练时期望为这些目标张量载入外部的numpy数据），你可以通过该参数手动指定。目标张量可以是一个单独的张量（对应于单输出模型），也可以是一个张量列表，或者一个name->tensor的张量字典。\n",
    "\tkwargs：            使用TensorFlow作为后端请忽略该参数，若使用Theano/CNTK作为后端，kwargs的值将会传递给 K.function。如果使用TensorFlow为后端，这里的值会被传给tf.Session.run\n",
    "\t在Keras中，compile主要完成损失函数和优化器的一些配置，是为训练服务的。\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/train/image/21_training.tif', 'data/train/image/22_training.tif', 'data/train/image/23_training.tif', 'data/train/image/24_training.tif', 'data/train/image/25_training.tif', 'data/train/image/26_training.tif', 'data/train/image/27_training.tif', 'data/train/image/28_training.tif', 'data/train/image/29_training.tif', 'data/train/image/30_training.tif', 'data/train/image/31_training.tif', 'data/train/image/32_training.tif', 'data/train/image/33_training.tif', 'data/train/image/34_training.tif', 'data/train/image/35_training.tif', 'data/train/image/36_training.tif', 'data/train/image/37_training.tif', 'data/train/image/38_training.tif', 'data/train/image/39_training.tif', 'data/train/image/40_training.tif']\n",
      "original images shape: (20, 592, 576, 3)\n",
      "['data/train/mask/21_training.tif', 'data/train/mask/22_training.tif', 'data/train/mask/23_training.tif', 'data/train/mask/24_training.tif', 'data/train/mask/25_training.tif', 'data/train/mask/26_training.tif', 'data/train/mask/27_training.tif', 'data/train/mask/28_training.tif', 'data/train/mask/29_training.tif', 'data/train/mask/30_training.tif', 'data/train/mask/31_training.tif', 'data/train/mask/32_training.tif', 'data/train/mask/33_training.tif', 'data/train/mask/34_training.tif', 'data/train/mask/35_training.tif', 'data/train/mask/36_training.tif', 'data/train/mask/37_training.tif', 'data/train/mask/38_training.tif', 'data/train/mask/39_training.tif', 'data/train/mask/40_training.tif']\n",
      "original labels shape: (20, 592, 576, 3)\n",
      "X_train.shape(20, 576, 576, 3)\n",
      "Y_train.shape(20, 576, 576, 3)\n",
      "Y_train shape: (2880, 48, 48)\n",
      "Y_train shape: (2880, 2304)\n",
      "Y_train shape: (2880, 2304, 1)\n",
      "Y_train shape: (2880, 2304, 2)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 48, 48)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 48, 48)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 48, 48)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 48, 48)   9248        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 16, 24, 48)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 24, 48)   9280        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 24, 48)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 24, 48)   36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 12, 48)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 12, 48)  36992       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 12, 48)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 12, 48)  147584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 256, 24, 48)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 320, 24, 48)  0           conv2d_3[0][0]                   \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 24, 48)   184384      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 24, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 24, 48)   36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 48, 48)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 160, 48, 48)  0           conv2d_1[0][0]                   \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 48, 48)   46112       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 48, 48)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 48, 48)   9248        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 2, 48, 48)    66          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 2, 2304)      0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 2304, 2)      0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2304, 2)      0           permute[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 517,666\n",
      "Trainable params: 517,666\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.0559s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0140s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91887, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.3454 - accuracy: 0.8728 - val_loss: 0.2478 - val_accuracy: 0.9189\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.91887\n",
      "36/36 - 2s - loss: 0.2541 - accuracy: 0.9159 - val_loss: 0.2453 - val_accuracy: 0.9189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91887\n",
      "36/36 - 2s - loss: 0.2524 - accuracy: 0.9159 - val_loss: 0.2435 - val_accuracy: 0.9189\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.91887\n",
      "36/36 - 2s - loss: 0.2500 - accuracy: 0.9159 - val_loss: 0.2372 - val_accuracy: 0.9189\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91887\n",
      "36/36 - 2s - loss: 0.2369 - accuracy: 0.9159 - val_loss: 0.1964 - val_accuracy: 0.9189\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91887 to 0.93869, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.2011 - accuracy: 0.9281 - val_loss: 0.1744 - val_accuracy: 0.9387\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.93869 to 0.94508, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1819 - accuracy: 0.9366 - val_loss: 0.1553 - val_accuracy: 0.9451\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.94508 to 0.95094, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1598 - accuracy: 0.9437 - val_loss: 0.1406 - val_accuracy: 0.9509\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.95094 to 0.95471, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1405 - accuracy: 0.9505 - val_loss: 0.1292 - val_accuracy: 0.9547\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.95471 to 0.95765, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1372 - accuracy: 0.9516 - val_loss: 0.1161 - val_accuracy: 0.9576\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.95765 to 0.95831, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1298 - accuracy: 0.9544 - val_loss: 0.1141 - val_accuracy: 0.9583\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.95831 to 0.95930, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1286 - accuracy: 0.9546 - val_loss: 0.1097 - val_accuracy: 0.9593\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.95930 to 0.96071, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1212 - accuracy: 0.9569 - val_loss: 0.1055 - val_accuracy: 0.9607\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.96071\n",
      "36/36 - 2s - loss: 0.1211 - accuracy: 0.9571 - val_loss: 0.1063 - val_accuracy: 0.9604\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.96071 to 0.96088, saving model to best_weights.h5\n",
      "36/36 - 2s - loss: 0.1177 - accuracy: 0.9582 - val_loss: 0.1035 - val_accuracy: 0.9609\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.96088 to 0.96175, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1168 - accuracy: 0.9583 - val_loss: 0.1041 - val_accuracy: 0.9617\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.96175 to 0.96195, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1146 - accuracy: 0.9589 - val_loss: 0.1010 - val_accuracy: 0.9620\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.96195 to 0.96273, saving model to best_weights.h5\n",
      "36/36 - 3s - loss: 0.1130 - accuracy: 0.9596 - val_loss: 0.1003 - val_accuracy: 0.9627\n",
      "Epoch 19/20\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#参数和路径\n",
    "resize_height, resize_width = (576, 576)\n",
    "dx = 48\n",
    "# img_path = 'DRIVE/training/images/'\n",
    "# label_path = 'DRIVE/training/1st_manual/'\n",
    "img_path = 'data/train/image/'\n",
    "label_path = 'data/train/mask/'\n",
    "\n",
    "\n",
    "#读取数据并resize\n",
    "imglst,images = read_image_and_name(img_path)\n",
    "labellst,labels = read_label_and_name(label_path)\n",
    "imgs_resize = resize(images,resize_height, resize_width)\n",
    "labels_resize = resize(labels,resize_height, resize_width)\n",
    "\n",
    "#将imgs列表和manuals列表转换成numpy数组\n",
    "X_train = np.array(imgs_resize)\n",
    "Y_train = np.array(labels_resize)\n",
    "print('X_train.shape'+str(X_train.shape))\n",
    "print('Y_train.shape'+str(Y_train.shape))\n",
    "\n",
    "#标准化\n",
    "X_train = X_train.astype('float32')/255\n",
    "Y_train = Y_train.astype('float32')/255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#将Y_train改为单通道？？\n",
    "Y_train=Y_train[...,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #提取训练集的G通道\n",
    "# X_train = X_train[...,1]\n",
    "\n",
    "# #对训练数据进行裁剪\n",
    "# X_train = crop(X_train,dx)\n",
    "# Y_train = crop(Y_train,dx)\n",
    "# print('X_train shape: '+str(X_train.shape)) #X_train(2880,48,48)\n",
    "# print('Y_train shape: '+str(Y_train.shape)) #Y_train(2880,48,48)\n",
    "\n",
    "# #X_train增加一维变成(2880,1,48,48)\n",
    "# X_train = X_train[:,np.newaxis, ...]\n",
    "# print('X_train shape: '+str(X_train.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#将单通道转换为三通道\n",
    "X_train_0=X_train[...,0]\n",
    "X_train_1=X_train[...,1]\n",
    "X_train_2=X_train[...,2]\n",
    "X_train_0 = crop(X_train_0,dx)\n",
    "X_train_1 = crop(X_train_1,dx)\n",
    "X_train_2 = crop(X_train_2,dx)\n",
    "Y_train = crop(Y_train,dx)\n",
    "X_train_0 = X_train_0[:,np.newaxis, ...]\n",
    "X_train_1 = X_train_1[:,np.newaxis, ...]\n",
    "X_train_2 = X_train_2[:,np.newaxis, ...]\n",
    "print('Y_train shape: '+str(Y_train.shape)) #Y_train(2880,48,48)\n",
    "X_train=np.concatenate((X_train_0,X_train_1,X_train_2),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#Y_train改变shape变成(2880,2304),保持第一维不变，其他维合并\n",
    "Y_train = Y_train.reshape(Y_train.shape[0],-1)\n",
    "print('Y_train shape: '+str(Y_train.shape))\n",
    "Y_train =Y_train[..., np.newaxis]  #增加一维变成(2880,2304,1)\n",
    "print('Y_train shape: '+str(Y_train.shape))\n",
    "temp = 1 - Y_train\n",
    "Y_train = np.concatenate([Y_train, temp], axis=2) #变成(2880,2304,2)\n",
    "print('Y_train shape: '+str(Y_train.shape))\n",
    "\n",
    "#获得model\n",
    "model = get_unet(X_train.shape[1],X_train.shape[2],X_train.shape[3])\n",
    "model.summary() #输出参数Param计算过程\n",
    "checkpointer = ModelCheckpoint(filepath='best_weights.h5',verbose=1,monitor='val_accuracy',mode='auto',save_best_only=True)\n",
    "model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,batch_size=64,epochs=20,verbose=2,shuffle=True,validation_split=0.2,callbacks=[checkpointer])\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "resize_height, resize_width = (576, 576)\n",
    "dx = 48\n",
    "#读取预测图片\n",
    "# imgs = cv2.imread('data/test/images/01_test.tif')[...,1] #读取G通道\n",
    "imgs = cv2.imread('data/test/images/01_test.tif') #读取G通道\n",
    "imgs = np.array(cv2.resize(imgs,(resize_height,resize_width))) #imgs现在是576x576大小\n",
    "#读取预测图片的标签\n",
    "label = np.array(Image.open('data/test/mask/01_test.tif'))\n",
    "print(label.shape)\n",
    "\n",
    "\n",
    "label = np.array(cv2.resize(label,(resize_height, resize_width)))\n",
    "print(label.shape)\n",
    "\n",
    "\n",
    "\n",
    "#预测图片和标签标准化\n",
    "X_test = imgs.astype('float32')/255\n",
    "print('X_test original shape: '+str(X_test.shape))\n",
    "Y_test = label.astype('float32')/255\n",
    "\n",
    "\n",
    "#对预测图片进行裁剪按行优先，裁剪成(144,48,48)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# list = []\n",
    "# for i in range(resize_height//dx):\n",
    "#     for j in range(resize_width//dx):\n",
    "#         list.append(X_test[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "# X_test = np.array(list)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test_0=X_test[...,0]\n",
    "X_test_1=X_test[...,1]\n",
    "X_test_2=X_test[...,2]\n",
    "list_0 = []\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        list_0.append(X_test_0[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "X_test_0 = np.array(list_0)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "list_1 = []\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        list_1.append(X_test_1[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "X_test_1 = np.array(list_1)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "list_2 = []\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        list_2.append(X_test_2[i*dx:(i+1)*dx, j*dx:(j+1)*dx])\n",
    "X_test_2 = np.array(list_2)[:,np.newaxis,...] #增加一维变成(144,1,48,48)\n",
    "\n",
    "\n",
    "#X_test换channel位置\n",
    "X_test=np.concatenate((X_test_0,X_test_1,X_test_2),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('input shape: '+str(X_test.shape))\n",
    "\n",
    "#加载模型和权重并预测\n",
    "model = get_unet(X_test.shape[1],X_test.shape[2],X_test.shape[3])\n",
    "\n",
    "\n",
    "model.load_weights('best_weights.h5')\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print('predict shape: '+str(Y_pred.shape)) #预测结果的shape是(Npatches,patch_height*patch_width,2)\n",
    "\n",
    "#把预测输出的numpy数组拼接还原再显示\n",
    "Y_pred = Y_pred[..., 0]  #二分类提取出分割前景 现在Y_pred的shape是(144,2304) 且这个144是按照行优先来拼接的\n",
    "\n",
    "#对预测结果进行拼接，将(144,2304)拼接成(576,576)\n",
    "t=0\n",
    "image = np.zeros((resize_height,resize_width))\n",
    "for i in range(resize_height//dx):\n",
    "    for j in range(resize_width//dx):\n",
    "        temp = Y_pred[t].reshape(dx,dx)\n",
    "        image[i*dx:(i+1)*dx, j*dx:(j+1)*dx] = temp\n",
    "        t = t+1\n",
    "image = cv2.resize(image,((Y_test.shape[1], Y_test.shape[0]))) #将576x576大小的图像还原成原图像大小\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(Y_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_0.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
