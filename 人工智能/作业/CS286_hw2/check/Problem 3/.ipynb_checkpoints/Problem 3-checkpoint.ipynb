{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3. BiLSTM-CRF (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you are expected to build a BiLSTM-CRF network model for named entity recognition (NER). \n",
    "The training, validation and testing datasets are English text, which have been provided below. The labels are tags of words in the text. \n",
    "\n",
    "The requirements are:\n",
    "\n",
    "1)\t[10 points] Build a BiLSTM-CRF model. If you use only the LSTM model, you will be given only half of the score. All code should be in the jupyter notebook. \n",
    "\n",
    "2)\t[5 points] The training module should include training and validation processes. The training and validation batch size should be 32. \n",
    "\n",
    "3)\t[5 points] Batches should have different max lengths. \n",
    "\n",
    "4)\t[5 points] Plot the training loss curve and validation loss curve based on each epoch. \n",
    "\n",
    "5)\t[5 points] Evaluate the test dataset by F1 score. \n",
    "\n",
    "Noteï¼šYou should write comments to explain what you have done for the important parts and why your code works for the above requirements. The given code for data preprocessing should not be changed.\n",
    "\n",
    "#### Reference: \n",
    "A paper for more information about sequence tagging problem and BiLSTM-CRF: https://arxiv.org/pdf/1603.01360.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an NER dataset for the training. Here is some preprocessing codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048560</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048561</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048562</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>rockets</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048563</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>exploded</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048564</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>upon</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word    Tag\n",
       "1048560  Sentence: 47958         of      O\n",
       "1048561  Sentence: 47958        the      O\n",
       "1048562  Sentence: 47958    rockets      O\n",
       "1048563  Sentence: 47958   exploded      O\n",
       "1048564  Sentence: 47958       upon      O\n",
       "1048565  Sentence: 47958     impact      O\n",
       "1048566  Sentence: 47958          .      O\n",
       "1048567  Sentence: 47959     Indian  B-gpe\n",
       "1048568  Sentence: 47959     forces      O\n",
       "1048569  Sentence: 47959       said      O\n",
       "1048570  Sentence: 47959       they      O\n",
       "1048571  Sentence: 47959  responded      O\n",
       "1048572  Sentence: 47959         to      O\n",
       "1048573  Sentence: 47959        the      O\n",
       "1048574  Sentence: 47959     attack      O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n",
    "data = data.drop(['POS'], axis =1)\n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes 35178 words and 17 different tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35178\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {}\n",
    "words = set(list(data['Word'].values))\n",
    "for w in words:\n",
    "    word_to_ix[w]=len(word_to_ix)\n",
    "n_words = len(words)\n",
    "print(n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "{'I-org': 0, 'B-gpe': 1, 'B-tim': 2, 'B-nat': 3, 'B-geo': 4, 'I-eve': 5, 'B-eve': 6, 'I-per': 7, 'O': 8, 'I-tim': 9, 'I-nat': 10, 'I-geo': 11, 'B-org': 12, 'I-art': 13, 'B-art': 14, 'B-per': 15, 'I-gpe': 16}\n"
     ]
    }
   ],
   "source": [
    "tag_dicts={}\n",
    "tags = set(list(data[\"Tag\"].values))\n",
    "for t in tags:\n",
    "    tag_dicts[t]=len(tag_dicts)\n",
    "n_tags = len(tags)\n",
    "print(n_tags)\n",
    "print(tag_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Israeli', 'B-gpe'), ('officials', 'O'), ('say', 'O'), ('Prime', 'B-per'), ('Minister', 'I-per'), ('Ariel', 'I-per'), ('Sharon', 'I-per'), ('will', 'O'), ('undergo', 'O'), ('a', 'O'), ('medical', 'O'), ('procedure', 'O'), ('Thursday', 'B-tim'), ('to', 'O'), ('close', 'O'), ('a', 'O'), ('tiny', 'O'), ('hole', 'O'), ('in', 'O'), ('his', 'O'), ('heart', 'O'), ('discovered', 'O'), ('during', 'O'), ('treatment', 'O'), ('for', 'O'), ('a', 'O'), ('minor', 'O'), ('stroke', 'O'), ('suffered', 'O'), ('last', 'O'), ('month', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
    "grouped = data.groupby(\"Sentence #\").apply(agg_func)\n",
    "sentences = [s for s in grouped]\n",
    "print(sentences[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should change the data into a sequence list and a tag list. Besides, we change the words and tags into dictionary indexes, which are easier to feed into the embeding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20731, 27809, 23435, 33831, 14278, 28646, 28798, 10565, 18082, 11320, 32605, 8275, 29662, 23702, 2864, 11320, 9218, 33694, 34569, 34817, 26892, 11644, 33227, 16522, 8380, 11320, 24477, 21909, 17088, 2970, 24587, 25245]\n",
      "[1, 8, 8, 15, 7, 7, 7, 8, 8, 8, 8, 8, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "max_len = 50\n",
    "X = [[w[0]for w in s] for s in sentences]\n",
    "Y = [[w[1]for w in s] for s in sentences]\n",
    "new_data = []\n",
    "new_tags=[]\n",
    "for seq,tag in zip(X,Y):\n",
    "    new_seq=[]\n",
    "    new_tag=[]\n",
    "    for i in range(max_len):\n",
    "        try:\n",
    "            new_seq.append(word_to_ix[seq[i]])\n",
    "            new_tag.append(tag_dicts[tag[i]])\n",
    "        except:\n",
    "            pass\n",
    "    new_data.append(new_seq)\n",
    "    new_tags.append(new_tag)\n",
    "print(new_data[15])\n",
    "print(new_tags[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_data, new_tags, test_size=0.3)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1. model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2. training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3. test module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
